{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building Predictive Models \n",
    "### for [Click-Through Rate Prediction](https://www.kaggle.com/c/avazu-ctr-prediction) by Avazu\n",
    "*Phong Nguyen, July 2019*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To recap from the previous EDA, we are tasked to build a **binary classification model** to predict the probability of an ad being clicked. In this notebook, I will go through a process of feature engineering, model training, parameter tunning and making predictions. \n",
    "\n",
    "As the dataset is huge, I will use a small sample of 100,000 events for faster processing. Then use the tuned parameters to build a model with a full dataset later. I also iteratively go through the model building process rather than doing exhaustive feature engineering first."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data loading and formatting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/lightgbm/__init__.py:46: UserWarning: Starting from version 2.2.1, the library file in distribution wheels for macOS is built by the Apple Clang (Xcode_8.3.3) compiler.\n",
      "This means that in case of installing LightGBM from PyPI via the ``pip install lightgbm`` command, you don't need to install the gcc compiler anymore.\n",
      "Instead of that, you need to install the OpenMP library, which is required for running LightGBM on the system with the Apple Clang compiler.\n",
      "You can install the OpenMP library by the following command: ``brew install libomp``.\n",
      "  \"You can install the OpenMP library by the following command: ``brew install libomp``.\", UserWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from scipy.sparse import hstack\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.feature_extraction import FeatureHasher\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "\n",
    "import gzip\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Will save the sample to a file for faster loading later\n",
    "train_size = 40428967\n",
    "already_sample = False\n",
    "\n",
    "if already_sample:\n",
    "    sample = pd.read_csv('sample-100k.csv', index_col=0)\n",
    "else:\n",
    "    sample_size = 10**5\n",
    "    skip = sorted(np.random.choice(np.arange(1, train_size + 1), train_size - sample_size, replace=False))\n",
    "    sample = pd.read_csv('train', skiprows=skip, index_col=0)\n",
    "    sample.to_csv('sample-100k.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_data(sample):\n",
    "    cat_attribs = sorted(set(sample.columns) - { 'hour', 'click' })\n",
    "    for c in cat_attribs:\n",
    "        sample[c] = sample[c].astype('category')\n",
    "\n",
    "    sample['hour'] = pd.to_datetime(sample['hour'], format='%y%m%d%H')\n",
    "    sample['click'] = sample['click'].astype(np.uint8)\n",
    "    \n",
    "    return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = format_data(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>unique</th>\n",
       "      <th>top</th>\n",
       "      <th>freq</th>\n",
       "      <th>first</th>\n",
       "      <th>last</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>click</th>\n",
       "      <td>100000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.17038</td>\n",
       "      <td>0.375968</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hour</th>\n",
       "      <td>100000</td>\n",
       "      <td>240</td>\n",
       "      <td>2014-10-22 09:00:00</td>\n",
       "      <td>1086</td>\n",
       "      <td>2014-10-21 00:00:00</td>\n",
       "      <td>2014-10-30 23:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C1</th>\n",
       "      <td>100000</td>\n",
       "      <td>7</td>\n",
       "      <td>1005</td>\n",
       "      <td>91932</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>banner_pos</th>\n",
       "      <td>100000</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>72118</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>site_id</th>\n",
       "      <td>100000</td>\n",
       "      <td>1465</td>\n",
       "      <td>85f751fd</td>\n",
       "      <td>36013</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>site_domain</th>\n",
       "      <td>100000</td>\n",
       "      <td>1319</td>\n",
       "      <td>c4e18dd6</td>\n",
       "      <td>37326</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>site_category</th>\n",
       "      <td>100000</td>\n",
       "      <td>20</td>\n",
       "      <td>50e219e0</td>\n",
       "      <td>40785</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>app_id</th>\n",
       "      <td>100000</td>\n",
       "      <td>1272</td>\n",
       "      <td>ecad2386</td>\n",
       "      <td>63987</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>app_domain</th>\n",
       "      <td>100000</td>\n",
       "      <td>91</td>\n",
       "      <td>7801e8d9</td>\n",
       "      <td>67415</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>app_category</th>\n",
       "      <td>100000</td>\n",
       "      <td>23</td>\n",
       "      <td>07d7df22</td>\n",
       "      <td>64785</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>device_id</th>\n",
       "      <td>100000</td>\n",
       "      <td>16695</td>\n",
       "      <td>a99f214a</td>\n",
       "      <td>82639</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>device_ip</th>\n",
       "      <td>100000</td>\n",
       "      <td>78074</td>\n",
       "      <td>6b9769f2</td>\n",
       "      <td>519</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>device_model</th>\n",
       "      <td>100000</td>\n",
       "      <td>3161</td>\n",
       "      <td>8a4875bd</td>\n",
       "      <td>6019</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>device_type</th>\n",
       "      <td>100000</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>92363</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>device_conn_type</th>\n",
       "      <td>100000</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>86320</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C14</th>\n",
       "      <td>100000</td>\n",
       "      <td>1706</td>\n",
       "      <td>4687</td>\n",
       "      <td>2344</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C15</th>\n",
       "      <td>100000</td>\n",
       "      <td>8</td>\n",
       "      <td>320</td>\n",
       "      <td>93238</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C16</th>\n",
       "      <td>100000</td>\n",
       "      <td>9</td>\n",
       "      <td>50</td>\n",
       "      <td>94331</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C17</th>\n",
       "      <td>100000</td>\n",
       "      <td>400</td>\n",
       "      <td>1722</td>\n",
       "      <td>10948</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C18</th>\n",
       "      <td>100000</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>41839</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C19</th>\n",
       "      <td>100000</td>\n",
       "      <td>63</td>\n",
       "      <td>35</td>\n",
       "      <td>29933</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C20</th>\n",
       "      <td>100000</td>\n",
       "      <td>154</td>\n",
       "      <td>-1</td>\n",
       "      <td>46813</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C21</th>\n",
       "      <td>100000</td>\n",
       "      <td>60</td>\n",
       "      <td>23</td>\n",
       "      <td>22038</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   count unique                  top   freq  \\\n",
       "click             100000    NaN                  NaN    NaN   \n",
       "hour              100000    240  2014-10-22 09:00:00   1086   \n",
       "C1                100000      7                 1005  91932   \n",
       "banner_pos        100000      7                    0  72118   \n",
       "site_id           100000   1465             85f751fd  36013   \n",
       "site_domain       100000   1319             c4e18dd6  37326   \n",
       "site_category     100000     20             50e219e0  40785   \n",
       "app_id            100000   1272             ecad2386  63987   \n",
       "app_domain        100000     91             7801e8d9  67415   \n",
       "app_category      100000     23             07d7df22  64785   \n",
       "device_id         100000  16695             a99f214a  82639   \n",
       "device_ip         100000  78074             6b9769f2    519   \n",
       "device_model      100000   3161             8a4875bd   6019   \n",
       "device_type       100000      4                    1  92363   \n",
       "device_conn_type  100000      4                    0  86320   \n",
       "C14               100000   1706                 4687   2344   \n",
       "C15               100000      8                  320  93238   \n",
       "C16               100000      9                   50  94331   \n",
       "C17               100000    400                 1722  10948   \n",
       "C18               100000      4                    0  41839   \n",
       "C19               100000     63                   35  29933   \n",
       "C20               100000    154                   -1  46813   \n",
       "C21               100000     60                   23  22038   \n",
       "\n",
       "                                first                 last     mean       std  \\\n",
       "click                             NaN                  NaN  0.17038  0.375968   \n",
       "hour              2014-10-21 00:00:00  2014-10-30 23:00:00      NaN       NaN   \n",
       "C1                                NaN                  NaN      NaN       NaN   \n",
       "banner_pos                        NaN                  NaN      NaN       NaN   \n",
       "site_id                           NaN                  NaN      NaN       NaN   \n",
       "site_domain                       NaN                  NaN      NaN       NaN   \n",
       "site_category                     NaN                  NaN      NaN       NaN   \n",
       "app_id                            NaN                  NaN      NaN       NaN   \n",
       "app_domain                        NaN                  NaN      NaN       NaN   \n",
       "app_category                      NaN                  NaN      NaN       NaN   \n",
       "device_id                         NaN                  NaN      NaN       NaN   \n",
       "device_ip                         NaN                  NaN      NaN       NaN   \n",
       "device_model                      NaN                  NaN      NaN       NaN   \n",
       "device_type                       NaN                  NaN      NaN       NaN   \n",
       "device_conn_type                  NaN                  NaN      NaN       NaN   \n",
       "C14                               NaN                  NaN      NaN       NaN   \n",
       "C15                               NaN                  NaN      NaN       NaN   \n",
       "C16                               NaN                  NaN      NaN       NaN   \n",
       "C17                               NaN                  NaN      NaN       NaN   \n",
       "C18                               NaN                  NaN      NaN       NaN   \n",
       "C19                               NaN                  NaN      NaN       NaN   \n",
       "C20                               NaN                  NaN      NaN       NaN   \n",
       "C21                               NaN                  NaN      NaN       NaN   \n",
       "\n",
       "                  min  25%  50%  75%  max  \n",
       "click               0    0    0    0    1  \n",
       "hour              NaN  NaN  NaN  NaN  NaN  \n",
       "C1                NaN  NaN  NaN  NaN  NaN  \n",
       "banner_pos        NaN  NaN  NaN  NaN  NaN  \n",
       "site_id           NaN  NaN  NaN  NaN  NaN  \n",
       "site_domain       NaN  NaN  NaN  NaN  NaN  \n",
       "site_category     NaN  NaN  NaN  NaN  NaN  \n",
       "app_id            NaN  NaN  NaN  NaN  NaN  \n",
       "app_domain        NaN  NaN  NaN  NaN  NaN  \n",
       "app_category      NaN  NaN  NaN  NaN  NaN  \n",
       "device_id         NaN  NaN  NaN  NaN  NaN  \n",
       "device_ip         NaN  NaN  NaN  NaN  NaN  \n",
       "device_model      NaN  NaN  NaN  NaN  NaN  \n",
       "device_type       NaN  NaN  NaN  NaN  NaN  \n",
       "device_conn_type  NaN  NaN  NaN  NaN  NaN  \n",
       "C14               NaN  NaN  NaN  NaN  NaN  \n",
       "C15               NaN  NaN  NaN  NaN  NaN  \n",
       "C16               NaN  NaN  NaN  NaN  NaN  \n",
       "C17               NaN  NaN  NaN  NaN  NaN  \n",
       "C18               NaN  NaN  NaN  NaN  NaN  \n",
       "C19               NaN  NaN  NaN  NaN  NaN  \n",
       "C20               NaN  NaN  NaN  NaN  NaN  \n",
       "C21               NaN  NaN  NaN  NaN  NaN  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample.describe(include='all').T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building a first simple model\n",
    "\n",
    "As we need to submit the probability of the prediction, **Logistic Regression** is a good first choice. I will build a first simple model with one attribute. `banner_pos` looks like a reasonable choice as the position of an ad can play a role in it being clicked. \n",
    "\n",
    "The performance metric is **logloss** as chosen by the competition organiser."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model with banner_pos: 0.45624931576686867\n"
     ]
    }
   ],
   "source": [
    "labels = sample['click']\n",
    "\n",
    "cat_attribs = ['banner_pos']\n",
    "train_data = sample[cat_attribs]\n",
    "onehot = OneHotEncoder(categories='auto', handle_unknown='ignore').fit(train_data)\n",
    "train_data_prepared = onehot.transform(train_data)\n",
    "\n",
    "logreg = LogisticRegression(solver='lbfgs', max_iter=500)\n",
    "s = cross_val_score(logreg, train_data_prepared, labels, scoring='neg_log_loss', cv=5).mean()\n",
    "print('Model with banner_pos:', -s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK, so what is the logloss for a naive model that always predicts the mean of CTR."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model predicting mean: 0.45648823999656146\n"
     ]
    }
   ],
   "source": [
    "m = labels.mean()\n",
    "print('Model predicting mean:', log_loss(labels, [m] * len(labels)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well, the naive mean model is just a little bit worse than my first model with `banner_pos`. Good start anyway. I want to make a kaggle submission."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4577464 entries, 0 to 4577463\n",
      "Data columns (total 23 columns):\n",
      "id                  uint64\n",
      "hour                int64\n",
      "C1                  int64\n",
      "banner_pos          int64\n",
      "site_id             object\n",
      "site_domain         object\n",
      "site_category       object\n",
      "app_id              object\n",
      "app_domain          object\n",
      "app_category        object\n",
      "device_id           object\n",
      "device_ip           object\n",
      "device_model        object\n",
      "device_type         int64\n",
      "device_conn_type    int64\n",
      "C14                 int64\n",
      "C15                 int64\n",
      "C16                 int64\n",
      "C17                 int64\n",
      "C18                 int64\n",
      "C19                 int64\n",
      "C20                 int64\n",
      "C21                 int64\n",
      "dtypes: int64(13), object(9), uint64(1)\n",
      "memory usage: 803.2+ MB\n"
     ]
    }
   ],
   "source": [
    "click_data_test = pd.read_csv('test', dtype={ 'id': np.uint64 })\n",
    "click_data_test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cat_attribs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-379d550be9c0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclick_data_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcat_attribs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtest_data_prepared\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0monehot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mlogreg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data_prepared\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogreg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_data_prepared\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mpreds\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'cat_attribs' is not defined"
     ]
    }
   ],
   "source": [
    "test_data = click_data_test[cat_attribs]\n",
    "test_data_prepared = onehot.transform(test_data)\n",
    "logreg.fit(train_data_prepared, labels)\n",
    "preds = logreg.predict_proba(test_data_prepared)\n",
    "preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK, submit the second column. Export to csv then zip the file for fast uploading."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_submission_file(preds, data=click_data_test):\n",
    "    df = pd.DataFrame({ 'id': data['id'].values, 'click': preds[:, 1] })\n",
    "    df.set_index('id', inplace=True)\n",
    "    \n",
    "    with gzip.open('submission.gz', 'wt') as f:\n",
    "        f.write(df.to_csv())\n",
    "    \n",
    "generate_submission_file(preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I got **0.44091** for public leaderboard and a projected rank of 1387. At least, I got some ranking now and a baseline to improve. We save the model and keep track of its metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_models = [] # Store model name, information, logloss, projected rank, training size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(m, info, logloss, rank, size=len(sample)):\n",
    "    filename = 'saved-models/model-' + str(len(all_models) + 1) + '.pkl'\n",
    "    with open(filename, 'wb') as f:\n",
    "        pickle.dump(m, f)\n",
    "    all_models.append((filename, info, logloss, rank, size))\n",
    "    \n",
    "save_model(logreg, 'banner_pos only', 0.44091, 1387)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('model-1.pkl', 'banner_pos only', 0.44091, 1387, 100000)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Improving the model with feature engineering\n",
    "### Low-cardinality categorical features\n",
    "Next is to add more categorical features to the model, starting with low-cardinality ones as `banner_pos` before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model with low-cardinality attributes: 0.43247418615169614\n"
     ]
    }
   ],
   "source": [
    "cat_attribs = ['banner_pos', 'site_category', 'app_category', 'device_type', 'device_conn_type', 'C1', 'C15', 'C16', 'C18']\n",
    "train_data = sample[cat_attribs]\n",
    "onehot = OneHotEncoder(categories='auto', handle_unknown='ignore').fit(train_data)\n",
    "train_data_prepared = onehot.transform(train_data)\n",
    "\n",
    "logreg = LogisticRegression(solver='lbfgs', max_iter=500)\n",
    "s = cross_val_score(logreg, train_data_prepared, labels, scoring='neg_log_loss', cv=5).mean()\n",
    "print('Model with low-cardinality attributes:', -s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! The score gets lower than before. Make the second submission now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = click_data_test[cat_attribs]\n",
    "test_data_prepared = onehot.transform(test_data)\n",
    "logreg.fit(train_data_prepared, labels)\n",
    "preds = logreg.predict_proba(test_data_prepared)\n",
    "generate_submission_file(preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PL 0.41861, well much lower than the score in our model training. It's ranked 1208. OK, save the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model(logreg, 'low-cardinality features', 0.41861, 1208)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### High-cardinality categorical features\n",
    "Onehot encoding features with a high number of categories creates a high number of features, which could cause overfitting and suffer from the curse of dimensionality. Instead, I will apply feature hashing to control the number of features produced. I won't use `device_id` and `device_ip` as the their cardinalities are too high and they act as ID fields. `C20` has missing values encoded as `-1`. This is actually fine to consider missing values as another category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model with all categorical attributes: 0.42200277489033605\n"
     ]
    }
   ],
   "source": [
    "cat_attribs = ['C1', 'banner_pos', 'site_category', 'app_category', 'device_type', 'device_conn_type', 'site_id', \n",
    "               'site_domain', 'app_id', 'app_domain', 'device_model', 'C14', 'C15', 'C16', 'C17', 'C18', 'C19', 'C20']\n",
    "\n",
    "# FeatureHasher requires string input instead of number\n",
    "for a in cat_attribs:\n",
    "    sample[a] = sample[a].astype('str')\n",
    "    \n",
    "train_data = sample[cat_attribs]\n",
    "hasher = FeatureHasher(n_features=500, input_type='string')\n",
    "train_data_prepared = hasher.transform(train_data.values)\n",
    "\n",
    "logreg = LogisticRegression(solver='lbfgs', max_iter=500)\n",
    "s = cross_val_score(logreg, train_data_prepared, labels, scoring='neg_log_loss', cv=5).mean()\n",
    "print('Model with all categorical attributes:', -s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make another submission. The training score is better than using only low-cardinality attributes, but how's about the final prediction?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "test_data = click_data_test[cat_attribs]\n",
    "for a in cat_attribs:\n",
    "    test_data[a] = test_data[a].astype('str')\n",
    "    \n",
    "test_data_prepared = hasher.transform(test_data.values)\n",
    "logreg.fit(train_data_prepared, labels)\n",
    "preds = logreg.predict_proba(test_data_prepared)\n",
    "generate_submission_file(preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PL 0.41605, a tiny improvement and ranked  much lower than the score in our model training. It's ranked 1191. OK, save the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model(logreg, 'all categorical features with feature hashing', 0.41605, 1191)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `hour` feature\n",
    "This temporal feature is the only one left. As explored previously, we can derive two more features: hour of the day and day of the week."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/data.py:645: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/base.py:464: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n"
     ]
    }
   ],
   "source": [
    "sample['hour_of_day'] = sample['hour'].dt.hour\n",
    "sample['day_of_week'] = sample['hour'].dt.weekday\n",
    "num_attribs = ['hour_of_day', 'day_of_week']\n",
    "\n",
    "# Feature scaling\n",
    "scaler = StandardScaler()\n",
    "num_data = scaler.fit_transform(sample[num_attribs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_attribs = ['C1', 'banner_pos', 'site_category', 'app_category', 'device_type', 'device_conn_type', 'site_id', \n",
    "               'site_domain', 'app_id', 'app_domain', 'device_model', 'C14', 'C15', 'C16', 'C17', 'C18', 'C19', 'C20']\n",
    "\n",
    "# FeatureHasher requires string input instead of number\n",
    "for a in cat_attribs:\n",
    "    sample[a] = sample[a].astype('str')\n",
    "    \n",
    "hasher = FeatureHasher(n_features=500, input_type='string')\n",
    "cat_data = hasher.transform(sample[cat_attribs].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num data: (100000, 2)\n",
      "Cat data: (100000, 500)\n"
     ]
    }
   ],
   "source": [
    "print('Num data:', num_data.shape)\n",
    "print('Cat data:', cat_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model with all categorical attributes: 0.42306352082587306\n"
     ]
    }
   ],
   "source": [
    "train_data_prepared = hstack([num_data, cat_data])\n",
    "logreg = LogisticRegression(solver='lbfgs', max_iter=500)\n",
    "s = cross_val_score(logreg, train_data_prepared, labels, scoring='neg_log_loss', cv=5).mean()\n",
    "print('Model with all categorical attributes:', -s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model doesn't improve though! So, I won't use those features. For the time allowed, I will stop the feature engineering here and move on to model tuning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tuning models\n",
    "I will tune the current logistic regression classifier and also consider more complex ensemble methods such as random forest and gradient boosting. First is to get the training data, which includes categorical attributes as described earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_attribs = ['C1', 'banner_pos', 'site_category', 'app_category', 'device_type', 'device_conn_type', 'site_id', \n",
    "               'site_domain', 'app_id', 'app_domain', 'device_model', 'C14', 'C15', 'C16', 'C17', 'C18', 'C19', 'C20']\n",
    "\n",
    "# FeatureHasher requires string input instead of number\n",
    "for a in cat_attribs:\n",
    "    sample[a] = sample[a].astype('str')\n",
    "    \n",
    "train_data = sample[cat_attribs]\n",
    "hasher = FeatureHasher(n_features=500, input_type='string')\n",
    "train_data_prepared = hasher.transform(train_data.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression\n",
    "Consider different values of the regularisation, solver and penalty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "[CV] C=0.01, penalty=l2, solver=lbfgs ................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  C=0.01, penalty=l2, solver=lbfgs, score=-0.42401528560770063, total=   0.9s\n",
      "[CV] C=0.01, penalty=l2, solver=lbfgs ................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.9s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  C=0.01, penalty=l2, solver=lbfgs, score=-0.4250853864017236, total=   0.8s\n",
      "[CV] C=0.01, penalty=l2, solver=lbfgs ................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    1.7s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  C=0.01, penalty=l2, solver=lbfgs, score=-0.4177317788456098, total=   0.8s\n",
      "[CV] C=0.01, penalty=l2, solver=lbfgs ................................\n",
      "[CV]  C=0.01, penalty=l2, solver=lbfgs, score=-0.41417544165541265, total=   0.7s\n",
      "[CV] C=0.01, penalty=l2, solver=lbfgs ................................\n",
      "[CV]  C=0.01, penalty=l2, solver=lbfgs, score=-0.4217239113306176, total=   0.7s\n",
      "[CV] C=0.1, penalty=l2, solver=lbfgs .................................\n",
      "[CV]  C=0.1, penalty=l2, solver=lbfgs, score=-0.4226891529771033, total=   1.5s\n",
      "[CV] C=0.1, penalty=l2, solver=lbfgs .................................\n",
      "[CV]  C=0.1, penalty=l2, solver=lbfgs, score=-0.42624054338678347, total=   1.5s\n",
      "[CV] C=0.1, penalty=l2, solver=lbfgs .................................\n",
      "[CV]  C=0.1, penalty=l2, solver=lbfgs, score=-0.41772792950904525, total=   1.5s\n",
      "[CV] C=0.1, penalty=l2, solver=lbfgs .................................\n",
      "[CV]  C=0.1, penalty=l2, solver=lbfgs, score=-0.412415578139203, total=   1.4s\n",
      "[CV] C=0.1, penalty=l2, solver=lbfgs .................................\n",
      "[CV]  C=0.1, penalty=l2, solver=lbfgs, score=-0.4220452277555256, total=   1.3s\n",
      "[CV] C=1, penalty=l2, solver=lbfgs ...................................\n",
      "[CV]  C=1, penalty=l2, solver=lbfgs, score=-0.4249485418699464, total=   1.9s\n",
      "[CV] C=1, penalty=l2, solver=lbfgs ...................................\n",
      "[CV]  C=1, penalty=l2, solver=lbfgs, score=-0.4282613466530651, total=   1.9s\n",
      "[CV] C=1, penalty=l2, solver=lbfgs ...................................\n",
      "[CV]  C=1, penalty=l2, solver=lbfgs, score=-0.41895718131465176, total=   1.6s\n",
      "[CV] C=1, penalty=l2, solver=lbfgs ...................................\n",
      "[CV]  C=1, penalty=l2, solver=lbfgs, score=-0.4136641312859303, total=   1.8s\n",
      "[CV] C=1, penalty=l2, solver=lbfgs ...................................\n",
      "[CV]  C=1, penalty=l2, solver=lbfgs, score=-0.4241826733280867, total=   2.0s\n",
      "[CV] C=10, penalty=l2, solver=lbfgs ..................................\n",
      "[CV]  C=10, penalty=l2, solver=lbfgs, score=-0.42548538315251877, total=   2.1s\n",
      "[CV] C=10, penalty=l2, solver=lbfgs ..................................\n",
      "[CV]  C=10, penalty=l2, solver=lbfgs, score=-0.42864369654927553, total=   1.9s\n",
      "[CV] C=10, penalty=l2, solver=lbfgs ..................................\n",
      "[CV]  C=10, penalty=l2, solver=lbfgs, score=-0.41923345830994324, total=   2.1s\n",
      "[CV] C=10, penalty=l2, solver=lbfgs ..................................\n",
      "[CV]  C=10, penalty=l2, solver=lbfgs, score=-0.41398313405635256, total=   2.0s\n",
      "[CV] C=10, penalty=l2, solver=lbfgs ..................................\n",
      "[CV]  C=10, penalty=l2, solver=lbfgs, score=-0.4246125290147414, total=   2.2s\n",
      "[CV] C=0.01, penalty=l1, solver=liblinear ............................\n",
      "[CV]  C=0.01, penalty=l1, solver=liblinear, score=-0.43973577841768613, total=   1.8s\n",
      "[CV] C=0.01, penalty=l1, solver=liblinear ............................\n",
      "[CV]  C=0.01, penalty=l1, solver=liblinear, score=-0.43427203967341343, total=   2.4s\n",
      "[CV] C=0.01, penalty=l1, solver=liblinear ............................\n",
      "[CV]  C=0.01, penalty=l1, solver=liblinear, score=-0.4257153720631879, total=   2.2s\n",
      "[CV] C=0.01, penalty=l1, solver=liblinear ............................\n",
      "[CV]  C=0.01, penalty=l1, solver=liblinear, score=-0.42473467020475025, total=   2.3s\n",
      "[CV] C=0.01, penalty=l1, solver=liblinear ............................\n",
      "[CV]  C=0.01, penalty=l1, solver=liblinear, score=-0.4339443708784735, total=   1.8s\n",
      "[CV] C=0.01, penalty=l2, solver=liblinear ............................\n",
      "[CV]  C=0.01, penalty=l2, solver=liblinear, score=-0.4248885904597601, total=   0.4s\n",
      "[CV] C=0.01, penalty=l2, solver=liblinear ............................\n",
      "[CV]  C=0.01, penalty=l2, solver=liblinear, score=-0.4255976316582115, total=   0.4s\n",
      "[CV] C=0.01, penalty=l2, solver=liblinear ............................\n",
      "[CV]  C=0.01, penalty=l2, solver=liblinear, score=-0.41800783981811573, total=   0.4s\n",
      "[CV] C=0.01, penalty=l2, solver=liblinear ............................\n",
      "[CV]  C=0.01, penalty=l2, solver=liblinear, score=-0.4146041828305942, total=   0.4s\n",
      "[CV] C=0.01, penalty=l2, solver=liblinear ............................\n",
      "[CV]  C=0.01, penalty=l2, solver=liblinear, score=-0.42213158520911553, total=   0.4s\n",
      "[CV] C=0.1, penalty=l1, solver=liblinear .............................\n",
      "[CV]  C=0.1, penalty=l1, solver=liblinear, score=-0.422339348147012, total=   9.1s\n",
      "[CV] C=0.1, penalty=l1, solver=liblinear .............................\n",
      "[CV]  C=0.1, penalty=l1, solver=liblinear, score=-0.426196118918074, total=   5.8s\n",
      "[CV] C=0.1, penalty=l1, solver=liblinear .............................\n",
      "[CV]  C=0.1, penalty=l1, solver=liblinear, score=-0.41786944084516126, total=  10.4s\n",
      "[CV] C=0.1, penalty=l1, solver=liblinear .............................\n",
      "[CV]  C=0.1, penalty=l1, solver=liblinear, score=-0.41361255584540396, total=   7.3s\n",
      "[CV] C=0.1, penalty=l1, solver=liblinear .............................\n",
      "[CV]  C=0.1, penalty=l1, solver=liblinear, score=-0.4215368596925377, total=   9.3s\n",
      "[CV] C=0.1, penalty=l2, solver=liblinear .............................\n",
      "[CV]  C=0.1, penalty=l2, solver=liblinear, score=-0.4229978334988557, total=   0.7s\n",
      "[CV] C=0.1, penalty=l2, solver=liblinear .............................\n",
      "[CV]  C=0.1, penalty=l2, solver=liblinear, score=-0.42645098024853817, total=   0.7s\n",
      "[CV] C=0.1, penalty=l2, solver=liblinear .............................\n",
      "[CV]  C=0.1, penalty=l2, solver=liblinear, score=-0.41781697045194194, total=   0.6s\n",
      "[CV] C=0.1, penalty=l2, solver=liblinear .............................\n",
      "[CV]  C=0.1, penalty=l2, solver=liblinear, score=-0.41257883530646405, total=   0.7s\n",
      "[CV] C=0.1, penalty=l2, solver=liblinear .............................\n",
      "[CV]  C=0.1, penalty=l2, solver=liblinear, score=-0.421895351008205, total=   0.7s\n",
      "[CV] C=1, penalty=l1, solver=liblinear ...............................\n",
      "[CV]  C=1, penalty=l1, solver=liblinear, score=-0.4240130900523667, total=  18.0s\n",
      "[CV] C=1, penalty=l1, solver=liblinear ...............................\n",
      "[CV]  C=1, penalty=l1, solver=liblinear, score=-0.42794525586179655, total=  17.8s\n",
      "[CV] C=1, penalty=l1, solver=liblinear ...............................\n",
      "[CV]  C=1, penalty=l1, solver=liblinear, score=-0.4186001747385374, total=  19.7s\n",
      "[CV] C=1, penalty=l1, solver=liblinear ...............................\n",
      "[CV]  C=1, penalty=l1, solver=liblinear, score=-0.41333557758380624, total=  18.2s\n",
      "[CV] C=1, penalty=l1, solver=liblinear ...............................\n",
      "[CV]  C=1, penalty=l1, solver=liblinear, score=-0.4233914372940765, total=  19.6s\n",
      "[CV] C=1, penalty=l2, solver=liblinear ...............................\n",
      "[CV]  C=1, penalty=l2, solver=liblinear, score=-0.42498003961587655, total=   1.0s\n",
      "[CV] C=1, penalty=l2, solver=liblinear ...............................\n",
      "[CV]  C=1, penalty=l2, solver=liblinear, score=-0.42829752229460927, total=   1.0s\n",
      "[CV] C=1, penalty=l2, solver=liblinear ...............................\n",
      "[CV]  C=1, penalty=l2, solver=liblinear, score=-0.4189644347689842, total=   1.0s\n",
      "[CV] C=1, penalty=l2, solver=liblinear ...............................\n",
      "[CV]  C=1, penalty=l2, solver=liblinear, score=-0.41368183564875394, total=   1.0s\n",
      "[CV] C=1, penalty=l2, solver=liblinear ...............................\n",
      "[CV]  C=1, penalty=l2, solver=liblinear, score=-0.4240925958173983, total=   1.0s\n",
      "[CV] C=10, penalty=l1, solver=liblinear ..............................\n",
      "[CV]  C=10, penalty=l1, solver=liblinear, score=-0.4253782018730007, total=  19.6s\n",
      "[CV] C=10, penalty=l1, solver=liblinear ..............................\n",
      "[CV]  C=10, penalty=l1, solver=liblinear, score=-0.42864806006346673, total=  20.8s\n",
      "[CV] C=10, penalty=l1, solver=liblinear ..............................\n",
      "[CV]  C=10, penalty=l1, solver=liblinear, score=-0.41918466262655474, total=  21.7s\n",
      "[CV] C=10, penalty=l1, solver=liblinear ..............................\n",
      "[CV]  C=10, penalty=l1, solver=liblinear, score=-0.41395497063821185, total=  19.8s\n",
      "[CV] C=10, penalty=l1, solver=liblinear ..............................\n",
      "[CV]  C=10, penalty=l1, solver=liblinear, score=-0.42445600822170104, total=  21.9s\n",
      "[CV] C=10, penalty=l2, solver=liblinear ..............................\n",
      "[CV]  C=10, penalty=l2, solver=liblinear, score=-0.42548102891311673, total=   1.1s\n",
      "[CV] C=10, penalty=l2, solver=liblinear ..............................\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  C=10, penalty=l2, solver=liblinear, score=-0.4286537692111541, total=   1.0s\n",
      "[CV] C=10, penalty=l2, solver=liblinear ..............................\n",
      "[CV]  C=10, penalty=l2, solver=liblinear, score=-0.4192316099635951, total=   1.1s\n",
      "[CV] C=10, penalty=l2, solver=liblinear ..............................\n",
      "[CV]  C=10, penalty=l2, solver=liblinear, score=-0.4139797166239617, total=   0.9s\n",
      "[CV] C=10, penalty=l2, solver=liblinear ..............................\n",
      "[CV]  C=10, penalty=l2, solver=liblinear, score=-0.42460086113934115, total=   1.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  60 out of  60 | elapsed:  5.0min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "       estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=500, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=None, solver='liblinear',\n",
       "          tol=0.0001, verbose=0, warm_start=False),\n",
       "       fit_params=None, iid='warn', n_jobs=None,\n",
       "       param_grid=[{'C': [0.01, 0.1, 1, 10], 'solver': ['lbfgs'], 'penalty': ['l2']}, {'C': [0.01, 0.1, 1, 10], 'solver': ['liblinear'], 'penalty': ['l1', 'l2']}],\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='neg_log_loss', verbose=3)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg = LogisticRegression(solver='liblinear', max_iter=500)\n",
    "param_grid = [\n",
    "    { 'C': [0.01, 0.1, 1, 10], 'solver': ['lbfgs'], 'penalty': ['l2'] }, # lbfgs only support l2\n",
    "    { 'C': [0.01, 0.1, 1, 10], 'solver': ['liblinear'], 'penalty': ['l1', 'l2'] }\n",
    "]\n",
    "grid_search = GridSearchCV(logreg, param_grid, cv=5, scoring='neg_log_loss', verbose=3)\n",
    "grid_search.fit(train_data_prepared, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model {'C': 0.1, 'penalty': 'l2', 'solver': 'lbfgs'} 0.42022383104243677\n"
     ]
    }
   ],
   "source": [
    "print('Best model', grid_search.best_params_, -grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest\n",
    "The higher `n_estimators` the better the model is (like 100 or more?) but it will take time to run. So, I will set it to a small number for grid search. I will test the maximum depth and minimum number of points in a leaf node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n",
      "[CV] max_depth=50, min_samples_leaf=5 ................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_depth=50, min_samples_leaf=5, score=-0.41672167762302814, total=   6.3s\n",
      "[CV] max_depth=50, min_samples_leaf=5 ................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    6.8s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_depth=50, min_samples_leaf=5, score=-0.4191187530501353, total=   6.3s\n",
      "[CV] max_depth=50, min_samples_leaf=5 ................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:   13.6s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_depth=50, min_samples_leaf=5, score=-0.4195214198025711, total=   6.4s\n",
      "[CV] max_depth=50, min_samples_leaf=5 ................................\n",
      "[CV]  max_depth=50, min_samples_leaf=5, score=-0.41296529396967596, total=   6.3s\n",
      "[CV] max_depth=50, min_samples_leaf=5 ................................\n",
      "[CV]  max_depth=50, min_samples_leaf=5, score=-0.41853486496827946, total=   6.5s\n",
      "[CV] max_depth=50, min_samples_leaf=10 ...............................\n",
      "[CV]  max_depth=50, min_samples_leaf=10, score=-0.41596801122974675, total=   4.6s\n",
      "[CV] max_depth=50, min_samples_leaf=10 ...............................\n",
      "[CV]  max_depth=50, min_samples_leaf=10, score=-0.41908279522154085, total=   4.4s\n",
      "[CV] max_depth=50, min_samples_leaf=10 ...............................\n",
      "[CV]  max_depth=50, min_samples_leaf=10, score=-0.41462905498022684, total=   4.6s\n",
      "[CV] max_depth=50, min_samples_leaf=10 ...............................\n",
      "[CV]  max_depth=50, min_samples_leaf=10, score=-0.41168873558822106, total=   4.4s\n",
      "[CV] max_depth=50, min_samples_leaf=10 ...............................\n",
      "[CV]  max_depth=50, min_samples_leaf=10, score=-0.42023841596656547, total=   4.5s\n",
      "[CV] max_depth=50, min_samples_leaf=15 ...............................\n",
      "[CV]  max_depth=50, min_samples_leaf=15, score=-0.417448853745313, total=   3.7s\n",
      "[CV] max_depth=50, min_samples_leaf=15 ...............................\n",
      "[CV]  max_depth=50, min_samples_leaf=15, score=-0.41928499322702734, total=   3.6s\n",
      "[CV] max_depth=50, min_samples_leaf=15 ...............................\n",
      "[CV]  max_depth=50, min_samples_leaf=15, score=-0.41556195341639807, total=   3.6s\n",
      "[CV] max_depth=50, min_samples_leaf=15 ...............................\n",
      "[CV]  max_depth=50, min_samples_leaf=15, score=-0.41146077148792287, total=   3.7s\n",
      "[CV] max_depth=50, min_samples_leaf=15 ...............................\n",
      "[CV]  max_depth=50, min_samples_leaf=15, score=-0.4201992106916144, total=   3.7s\n",
      "[CV] max_depth=60, min_samples_leaf=5 ................................\n",
      "[CV]  max_depth=60, min_samples_leaf=5, score=-0.4154357338136672, total=   6.9s\n",
      "[CV] max_depth=60, min_samples_leaf=5 ................................\n",
      "[CV]  max_depth=60, min_samples_leaf=5, score=-0.41901432470818456, total=   7.1s\n",
      "[CV] max_depth=60, min_samples_leaf=5 ................................\n",
      "[CV]  max_depth=60, min_samples_leaf=5, score=-0.41965210177680456, total=   6.8s\n",
      "[CV] max_depth=60, min_samples_leaf=5 ................................\n",
      "[CV]  max_depth=60, min_samples_leaf=5, score=-0.41131103286773135, total=   6.9s\n",
      "[CV] max_depth=60, min_samples_leaf=5 ................................\n",
      "[CV]  max_depth=60, min_samples_leaf=5, score=-0.420324807310212, total=   7.0s\n",
      "[CV] max_depth=60, min_samples_leaf=10 ...............................\n",
      "[CV]  max_depth=60, min_samples_leaf=10, score=-0.4149626580755409, total=   4.6s\n",
      "[CV] max_depth=60, min_samples_leaf=10 ...............................\n",
      "[CV]  max_depth=60, min_samples_leaf=10, score=-0.4185946945139862, total=   4.8s\n",
      "[CV] max_depth=60, min_samples_leaf=10 ...............................\n",
      "[CV]  max_depth=60, min_samples_leaf=10, score=-0.41530274796049554, total=   4.9s\n",
      "[CV] max_depth=60, min_samples_leaf=10 ...............................\n",
      "[CV]  max_depth=60, min_samples_leaf=10, score=-0.4108456915967065, total=   4.7s\n",
      "[CV] max_depth=60, min_samples_leaf=10 ...............................\n",
      "[CV]  max_depth=60, min_samples_leaf=10, score=-0.41920057820488504, total=   4.8s\n",
      "[CV] max_depth=60, min_samples_leaf=15 ...............................\n",
      "[CV]  max_depth=60, min_samples_leaf=15, score=-0.41765409458973485, total=   3.9s\n",
      "[CV] max_depth=60, min_samples_leaf=15 ...............................\n",
      "[CV]  max_depth=60, min_samples_leaf=15, score=-0.41883105881705635, total=   3.8s\n",
      "[CV] max_depth=60, min_samples_leaf=15 ...............................\n",
      "[CV]  max_depth=60, min_samples_leaf=15, score=-0.41505973786667644, total=   3.8s\n",
      "[CV] max_depth=60, min_samples_leaf=15 ...............................\n",
      "[CV]  max_depth=60, min_samples_leaf=15, score=-0.41117021117609326, total=   3.8s\n",
      "[CV] max_depth=60, min_samples_leaf=15 ...............................\n",
      "[CV]  max_depth=60, min_samples_leaf=15, score=-0.41985254039011827, total=   3.9s\n",
      "[CV] max_depth=70, min_samples_leaf=5 ................................\n",
      "[CV]  max_depth=70, min_samples_leaf=5, score=-0.41526868023761343, total=   7.3s\n",
      "[CV] max_depth=70, min_samples_leaf=5 ................................\n",
      "[CV]  max_depth=70, min_samples_leaf=5, score=-0.4184762588838952, total=   7.7s\n",
      "[CV] max_depth=70, min_samples_leaf=5 ................................\n",
      "[CV]  max_depth=70, min_samples_leaf=5, score=-0.41806862579386544, total=   7.6s\n",
      "[CV] max_depth=70, min_samples_leaf=5 ................................\n",
      "[CV]  max_depth=70, min_samples_leaf=5, score=-0.411195508736111, total=   7.4s\n",
      "[CV] max_depth=70, min_samples_leaf=5 ................................\n",
      "[CV]  max_depth=70, min_samples_leaf=5, score=-0.41904582267712454, total=   7.5s\n",
      "[CV] max_depth=70, min_samples_leaf=10 ...............................\n",
      "[CV]  max_depth=70, min_samples_leaf=10, score=-0.4166858836922023, total=   4.8s\n",
      "[CV] max_depth=70, min_samples_leaf=10 ...............................\n",
      "[CV]  max_depth=70, min_samples_leaf=10, score=-0.4185297100007514, total=   5.0s\n",
      "[CV] max_depth=70, min_samples_leaf=10 ...............................\n",
      "[CV]  max_depth=70, min_samples_leaf=10, score=-0.41518472490231106, total=   5.1s\n",
      "[CV] max_depth=70, min_samples_leaf=10 ...............................\n",
      "[CV]  max_depth=70, min_samples_leaf=10, score=-0.4109544679774344, total=   5.0s\n",
      "[CV] max_depth=70, min_samples_leaf=10 ...............................\n",
      "[CV]  max_depth=70, min_samples_leaf=10, score=-0.4178723266589604, total=   4.9s\n",
      "[CV] max_depth=70, min_samples_leaf=15 ...............................\n",
      "[CV]  max_depth=70, min_samples_leaf=15, score=-0.41661209787117454, total=   3.8s\n",
      "[CV] max_depth=70, min_samples_leaf=15 ...............................\n",
      "[CV]  max_depth=70, min_samples_leaf=15, score=-0.4187670615164709, total=   4.0s\n",
      "[CV] max_depth=70, min_samples_leaf=15 ...............................\n",
      "[CV]  max_depth=70, min_samples_leaf=15, score=-0.4146196547677151, total=   4.0s\n",
      "[CV] max_depth=70, min_samples_leaf=15 ...............................\n",
      "[CV]  max_depth=70, min_samples_leaf=15, score=-0.41159882497626005, total=   4.0s\n",
      "[CV] max_depth=70, min_samples_leaf=15 ...............................\n",
      "[CV]  max_depth=70, min_samples_leaf=15, score=-0.4199608689075059, total=   4.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  45 out of  45 | elapsed:  4.2min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "       estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=20, n_jobs=None,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False),\n",
       "       fit_params=None, iid='warn', n_jobs=None,\n",
       "       param_grid={'max_depth': [50, 60, 70], 'min_samples_leaf': [5, 10, 15]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='neg_log_loss', verbose=3)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestClassifier(n_estimators=20)\n",
    "param_grid = { \n",
    "    'max_depth': [20, 40, 60, 80],\n",
    "    'min_samples_leaf': [5, 10, 15]\n",
    "}\n",
    "grid_search = GridSearchCV(rf, param_grid, cv=5, scoring='neg_log_loss', verbose=3)\n",
    "grid_search.fit(train_data_prepared, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model {'max_depth': 60, 'min_samples_leaf': 10} 0.4157813091811507\n"
     ]
    }
   ],
   "source": [
    "print('Best model', grid_search.best_params_, -grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! Even with a small number of estimators, random forest still produces a better result than logistic regression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boosting\n",
    "Now try gradient boosting with the popular `xgboost` library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 18 candidates, totalling 90 fits\n",
      "[CV] learning_rate=0.1, max_depth=5, min_child_weight=1 ..............\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  learning_rate=0.1, max_depth=5, min_child_weight=1, score=-0.43911590573966613, total=   3.1s\n",
      "[CV] learning_rate=0.1, max_depth=5, min_child_weight=1 ..............\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    3.6s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  learning_rate=0.1, max_depth=5, min_child_weight=1, score=-0.43745648687714056, total=   3.1s\n",
      "[CV] learning_rate=0.1, max_depth=5, min_child_weight=1 ..............\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    7.1s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  learning_rate=0.1, max_depth=5, min_child_weight=1, score=-0.4357060287293047, total=   3.1s\n",
      "[CV] learning_rate=0.1, max_depth=5, min_child_weight=1 ..............\n",
      "[CV]  learning_rate=0.1, max_depth=5, min_child_weight=1, score=-0.4297017507965526, total=   3.1s\n",
      "[CV] learning_rate=0.1, max_depth=5, min_child_weight=1 ..............\n",
      "[CV]  learning_rate=0.1, max_depth=5, min_child_weight=1, score=-0.43756616486478517, total=   3.1s\n",
      "[CV] learning_rate=0.1, max_depth=5, min_child_weight=3 ..............\n",
      "[CV]  learning_rate=0.1, max_depth=5, min_child_weight=3, score=-0.4392189771498712, total=   3.1s\n",
      "[CV] learning_rate=0.1, max_depth=5, min_child_weight=3 ..............\n",
      "[CV]  learning_rate=0.1, max_depth=5, min_child_weight=3, score=-0.4376722045779574, total=   3.1s\n",
      "[CV] learning_rate=0.1, max_depth=5, min_child_weight=3 ..............\n",
      "[CV]  learning_rate=0.1, max_depth=5, min_child_weight=3, score=-0.4334653632801026, total=   3.1s\n",
      "[CV] learning_rate=0.1, max_depth=5, min_child_weight=3 ..............\n",
      "[CV]  learning_rate=0.1, max_depth=5, min_child_weight=3, score=-0.4292961866009253, total=   3.1s\n",
      "[CV] learning_rate=0.1, max_depth=5, min_child_weight=3 ..............\n",
      "[CV]  learning_rate=0.1, max_depth=5, min_child_weight=3, score=-0.43723993535925254, total=   2.9s\n",
      "[CV] learning_rate=0.1, max_depth=10, min_child_weight=1 .............\n",
      "[CV]  learning_rate=0.1, max_depth=10, min_child_weight=1, score=-0.43122662469639633, total=   5.2s\n",
      "[CV] learning_rate=0.1, max_depth=10, min_child_weight=1 .............\n",
      "[CV]  learning_rate=0.1, max_depth=10, min_child_weight=1, score=-0.4321798149016337, total=   5.3s\n",
      "[CV] learning_rate=0.1, max_depth=10, min_child_weight=1 .............\n",
      "[CV]  learning_rate=0.1, max_depth=10, min_child_weight=1, score=-0.4370354653157294, total=   5.1s\n",
      "[CV] learning_rate=0.1, max_depth=10, min_child_weight=1 .............\n",
      "[CV]  learning_rate=0.1, max_depth=10, min_child_weight=1, score=-0.4232559563982599, total=   5.1s\n",
      "[CV] learning_rate=0.1, max_depth=10, min_child_weight=1 .............\n",
      "[CV]  learning_rate=0.1, max_depth=10, min_child_weight=1, score=-0.4301847096746239, total=   5.2s\n",
      "[CV] learning_rate=0.1, max_depth=10, min_child_weight=3 .............\n",
      "[CV]  learning_rate=0.1, max_depth=10, min_child_weight=3, score=-0.4321554478010734, total=   5.1s\n",
      "[CV] learning_rate=0.1, max_depth=10, min_child_weight=3 .............\n",
      "[CV]  learning_rate=0.1, max_depth=10, min_child_weight=3, score=-0.4319022043114227, total=   5.1s\n",
      "[CV] learning_rate=0.1, max_depth=10, min_child_weight=3 .............\n",
      "[CV]  learning_rate=0.1, max_depth=10, min_child_weight=3, score=-0.43124623790197075, total=   5.1s\n",
      "[CV] learning_rate=0.1, max_depth=10, min_child_weight=3 .............\n",
      "[CV]  learning_rate=0.1, max_depth=10, min_child_weight=3, score=-0.4229831638236458, total=   5.1s\n",
      "[CV] learning_rate=0.1, max_depth=10, min_child_weight=3 .............\n",
      "[CV]  learning_rate=0.1, max_depth=10, min_child_weight=3, score=-0.4305253735853318, total=   5.1s\n",
      "[CV] learning_rate=0.1, max_depth=20, min_child_weight=1 .............\n",
      "[CV]  learning_rate=0.1, max_depth=20, min_child_weight=1, score=-0.4295633334846599, total=   9.7s\n",
      "[CV] learning_rate=0.1, max_depth=20, min_child_weight=1 .............\n",
      "[CV]  learning_rate=0.1, max_depth=20, min_child_weight=1, score=-0.4333715730764277, total=   9.7s\n",
      "[CV] learning_rate=0.1, max_depth=20, min_child_weight=1 .............\n",
      "[CV]  learning_rate=0.1, max_depth=20, min_child_weight=1, score=-0.43862324052788315, total=   9.8s\n",
      "[CV] learning_rate=0.1, max_depth=20, min_child_weight=1 .............\n",
      "[CV]  learning_rate=0.1, max_depth=20, min_child_weight=1, score=-0.4234373489562151, total=   9.7s\n",
      "[CV] learning_rate=0.1, max_depth=20, min_child_weight=1 .............\n",
      "[CV]  learning_rate=0.1, max_depth=20, min_child_weight=1, score=-0.4298311687625553, total=   9.7s\n",
      "[CV] learning_rate=0.1, max_depth=20, min_child_weight=3 .............\n",
      "[CV]  learning_rate=0.1, max_depth=20, min_child_weight=3, score=-0.4291549355032283, total=   9.6s\n",
      "[CV] learning_rate=0.1, max_depth=20, min_child_weight=3 .............\n",
      "[CV]  learning_rate=0.1, max_depth=20, min_child_weight=3, score=-0.4320581187590719, total=   9.7s\n",
      "[CV] learning_rate=0.1, max_depth=20, min_child_weight=3 .............\n",
      "[CV]  learning_rate=0.1, max_depth=20, min_child_weight=3, score=-0.43234976091496646, total=   9.8s\n",
      "[CV] learning_rate=0.1, max_depth=20, min_child_weight=3 .............\n",
      "[CV]  learning_rate=0.1, max_depth=20, min_child_weight=3, score=-0.42302749913290705, total=   9.8s\n",
      "[CV] learning_rate=0.1, max_depth=20, min_child_weight=3 .............\n",
      "[CV]  learning_rate=0.1, max_depth=20, min_child_weight=3, score=-0.4295640858160811, total=   9.8s\n",
      "[CV] learning_rate=0.3, max_depth=5, min_child_weight=1 ..............\n",
      "[CV]  learning_rate=0.3, max_depth=5, min_child_weight=1, score=-0.42704479814979734, total=   3.0s\n",
      "[CV] learning_rate=0.3, max_depth=5, min_child_weight=1 ..............\n",
      "[CV]  learning_rate=0.3, max_depth=5, min_child_weight=1, score=-0.4232437564744114, total=   3.0s\n",
      "[CV] learning_rate=0.3, max_depth=5, min_child_weight=1 ..............\n",
      "[CV]  learning_rate=0.3, max_depth=5, min_child_weight=1, score=-0.42343336305441337, total=   3.0s\n",
      "[CV] learning_rate=0.3, max_depth=5, min_child_weight=1 ..............\n",
      "[CV]  learning_rate=0.3, max_depth=5, min_child_weight=1, score=-0.41576852777709145, total=   3.0s\n",
      "[CV] learning_rate=0.3, max_depth=5, min_child_weight=1 ..............\n",
      "[CV]  learning_rate=0.3, max_depth=5, min_child_weight=1, score=-0.4248095188420086, total=   3.0s\n",
      "[CV] learning_rate=0.3, max_depth=5, min_child_weight=3 ..............\n",
      "[CV]  learning_rate=0.3, max_depth=5, min_child_weight=3, score=-0.4283075284484388, total=   3.0s\n",
      "[CV] learning_rate=0.3, max_depth=5, min_child_weight=3 ..............\n",
      "[CV]  learning_rate=0.3, max_depth=5, min_child_weight=3, score=-0.4231921856459548, total=   3.0s\n",
      "[CV] learning_rate=0.3, max_depth=5, min_child_weight=3 ..............\n",
      "[CV]  learning_rate=0.3, max_depth=5, min_child_weight=3, score=-0.4198027276007459, total=   3.0s\n",
      "[CV] learning_rate=0.3, max_depth=5, min_child_weight=3 ..............\n",
      "[CV]  learning_rate=0.3, max_depth=5, min_child_weight=3, score=-0.415654602796834, total=   3.0s\n",
      "[CV] learning_rate=0.3, max_depth=5, min_child_weight=3 ..............\n",
      "[CV]  learning_rate=0.3, max_depth=5, min_child_weight=3, score=-0.4242556805408684, total=   3.0s\n",
      "[CV] learning_rate=0.3, max_depth=10, min_child_weight=1 .............\n",
      "[CV]  learning_rate=0.3, max_depth=10, min_child_weight=1, score=-0.42139954559035997, total=   5.0s\n",
      "[CV] learning_rate=0.3, max_depth=10, min_child_weight=1 .............\n",
      "[CV]  learning_rate=0.3, max_depth=10, min_child_weight=1, score=-0.42066681297993913, total=   5.0s\n",
      "[CV] learning_rate=0.3, max_depth=10, min_child_weight=1 .............\n",
      "[CV]  learning_rate=0.3, max_depth=10, min_child_weight=1, score=-0.4238815846712328, total=   5.0s\n",
      "[CV] learning_rate=0.3, max_depth=10, min_child_weight=1 .............\n",
      "[CV]  learning_rate=0.3, max_depth=10, min_child_weight=1, score=-0.41220171281210943, total=   5.2s\n",
      "[CV] learning_rate=0.3, max_depth=10, min_child_weight=1 .............\n",
      "[CV]  learning_rate=0.3, max_depth=10, min_child_weight=1, score=-0.421985130414629, total=   5.1s\n",
      "[CV] learning_rate=0.3, max_depth=10, min_child_weight=3 .............\n",
      "[CV]  learning_rate=0.3, max_depth=10, min_child_weight=3, score=-0.4200733835810283, total=   5.1s\n",
      "[CV] learning_rate=0.3, max_depth=10, min_child_weight=3 .............\n",
      "[CV]  learning_rate=0.3, max_depth=10, min_child_weight=3, score=-0.41972041639902286, total=   5.3s\n",
      "[CV] learning_rate=0.3, max_depth=10, min_child_weight=3 .............\n",
      "[CV]  learning_rate=0.3, max_depth=10, min_child_weight=3, score=-0.4194844751272351, total=   5.1s\n",
      "[CV] learning_rate=0.3, max_depth=10, min_child_weight=3 .............\n",
      "[CV]  learning_rate=0.3, max_depth=10, min_child_weight=3, score=-0.4136246132497062, total=   5.3s\n",
      "[CV] learning_rate=0.3, max_depth=10, min_child_weight=3 .............\n",
      "[CV]  learning_rate=0.3, max_depth=10, min_child_weight=3, score=-0.42317805424415694, total=   5.1s\n",
      "[CV] learning_rate=0.3, max_depth=20, min_child_weight=1 .............\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  learning_rate=0.3, max_depth=20, min_child_weight=1, score=-0.4228743030766487, total=   9.4s\n",
      "[CV] learning_rate=0.3, max_depth=20, min_child_weight=1 .............\n",
      "[CV]  learning_rate=0.3, max_depth=20, min_child_weight=1, score=-0.42599705736972865, total=   9.4s\n",
      "[CV] learning_rate=0.3, max_depth=20, min_child_weight=1 .............\n",
      "[CV]  learning_rate=0.3, max_depth=20, min_child_weight=1, score=-0.43324615997346116, total=   9.3s\n",
      "[CV] learning_rate=0.3, max_depth=20, min_child_weight=1 .............\n",
      "[CV]  learning_rate=0.3, max_depth=20, min_child_weight=1, score=-0.41772629707733433, total=   9.4s\n",
      "[CV] learning_rate=0.3, max_depth=20, min_child_weight=1 .............\n",
      "[CV]  learning_rate=0.3, max_depth=20, min_child_weight=1, score=-0.4278117293308992, total=   9.4s\n",
      "[CV] learning_rate=0.3, max_depth=20, min_child_weight=3 .............\n",
      "[CV]  learning_rate=0.3, max_depth=20, min_child_weight=3, score=-0.4203158865457552, total=   9.5s\n",
      "[CV] learning_rate=0.3, max_depth=20, min_child_weight=3 .............\n",
      "[CV]  learning_rate=0.3, max_depth=20, min_child_weight=3, score=-0.4219176701631984, total=   9.7s\n",
      "[CV] learning_rate=0.3, max_depth=20, min_child_weight=3 .............\n",
      "[CV]  learning_rate=0.3, max_depth=20, min_child_weight=3, score=-0.42590968153388237, total=   9.4s\n",
      "[CV] learning_rate=0.3, max_depth=20, min_child_weight=3 .............\n",
      "[CV]  learning_rate=0.3, max_depth=20, min_child_weight=3, score=-0.41605867417928316, total=   9.6s\n",
      "[CV] learning_rate=0.3, max_depth=20, min_child_weight=3 .............\n",
      "[CV]  learning_rate=0.3, max_depth=20, min_child_weight=3, score=-0.4240038508269782, total=   9.7s\n",
      "[CV] learning_rate=1, max_depth=5, min_child_weight=1 ................\n",
      "[CV]  learning_rate=1, max_depth=5, min_child_weight=1, score=-0.437277290286577, total=   3.1s\n",
      "[CV] learning_rate=1, max_depth=5, min_child_weight=1 ................\n",
      "[CV]  learning_rate=1, max_depth=5, min_child_weight=1, score=-0.43511489960658584, total=   3.1s\n",
      "[CV] learning_rate=1, max_depth=5, min_child_weight=1 ................\n",
      "[CV]  learning_rate=1, max_depth=5, min_child_weight=1, score=-0.429898518577544, total=   3.0s\n",
      "[CV] learning_rate=1, max_depth=5, min_child_weight=1 ................\n",
      "[CV]  learning_rate=1, max_depth=5, min_child_weight=1, score=-0.4171709332012681, total=   3.1s\n",
      "[CV] learning_rate=1, max_depth=5, min_child_weight=1 ................\n",
      "[CV]  learning_rate=1, max_depth=5, min_child_weight=1, score=-0.426175084609198, total=   3.1s\n",
      "[CV] learning_rate=1, max_depth=5, min_child_weight=3 ................\n",
      "[CV]  learning_rate=1, max_depth=5, min_child_weight=3, score=-0.43736654241364414, total=   3.1s\n",
      "[CV] learning_rate=1, max_depth=5, min_child_weight=3 ................\n",
      "[CV]  learning_rate=1, max_depth=5, min_child_weight=3, score=-0.4289560900003187, total=   3.0s\n",
      "[CV] learning_rate=1, max_depth=5, min_child_weight=3 ................\n",
      "[CV]  learning_rate=1, max_depth=5, min_child_weight=3, score=-0.4233152770577697, total=   3.1s\n",
      "[CV] learning_rate=1, max_depth=5, min_child_weight=3 ................\n",
      "[CV]  learning_rate=1, max_depth=5, min_child_weight=3, score=-0.41747183966481083, total=   3.0s\n",
      "[CV] learning_rate=1, max_depth=5, min_child_weight=3 ................\n",
      "[CV]  learning_rate=1, max_depth=5, min_child_weight=3, score=-0.4313038058691815, total=   3.1s\n",
      "[CV] learning_rate=1, max_depth=10, min_child_weight=1 ...............\n",
      "[CV]  learning_rate=1, max_depth=10, min_child_weight=1, score=-0.43973164597393216, total=   5.1s\n",
      "[CV] learning_rate=1, max_depth=10, min_child_weight=1 ...............\n",
      "[CV]  learning_rate=1, max_depth=10, min_child_weight=1, score=-0.4368237654407371, total=   5.1s\n",
      "[CV] learning_rate=1, max_depth=10, min_child_weight=1 ...............\n",
      "[CV]  learning_rate=1, max_depth=10, min_child_weight=1, score=-0.4353505967520876, total=   5.2s\n",
      "[CV] learning_rate=1, max_depth=10, min_child_weight=1 ...............\n",
      "[CV]  learning_rate=1, max_depth=10, min_child_weight=1, score=-0.42924802137621076, total=   5.2s\n",
      "[CV] learning_rate=1, max_depth=10, min_child_weight=1 ...............\n",
      "[CV]  learning_rate=1, max_depth=10, min_child_weight=1, score=-0.43983271298269067, total=   5.4s\n",
      "[CV] learning_rate=1, max_depth=10, min_child_weight=3 ...............\n",
      "[CV]  learning_rate=1, max_depth=10, min_child_weight=3, score=-0.430175940350544, total=   5.4s\n",
      "[CV] learning_rate=1, max_depth=10, min_child_weight=3 ...............\n",
      "[CV]  learning_rate=1, max_depth=10, min_child_weight=3, score=-0.4318987903606579, total=   5.4s\n",
      "[CV] learning_rate=1, max_depth=10, min_child_weight=3 ...............\n",
      "[CV]  learning_rate=1, max_depth=10, min_child_weight=3, score=-0.43611779140178697, total=   5.3s\n",
      "[CV] learning_rate=1, max_depth=10, min_child_weight=3 ...............\n",
      "[CV]  learning_rate=1, max_depth=10, min_child_weight=3, score=-0.4252036525309174, total=   5.2s\n",
      "[CV] learning_rate=1, max_depth=10, min_child_weight=3 ...............\n",
      "[CV]  learning_rate=1, max_depth=10, min_child_weight=3, score=-0.4352190251243942, total=   5.2s\n",
      "[CV] learning_rate=1, max_depth=20, min_child_weight=1 ...............\n",
      "[CV]  learning_rate=1, max_depth=20, min_child_weight=1, score=-0.46803157177220556, total=   9.7s\n",
      "[CV] learning_rate=1, max_depth=20, min_child_weight=1 ...............\n",
      "[CV]  learning_rate=1, max_depth=20, min_child_weight=1, score=-0.4559167486052689, total=  10.2s\n",
      "[CV] learning_rate=1, max_depth=20, min_child_weight=1 ...............\n",
      "[CV]  learning_rate=1, max_depth=20, min_child_weight=1, score=-0.4654212286577924, total=  10.1s\n",
      "[CV] learning_rate=1, max_depth=20, min_child_weight=1 ...............\n",
      "[CV]  learning_rate=1, max_depth=20, min_child_weight=1, score=-0.44993469479825865, total=  10.6s\n",
      "[CV] learning_rate=1, max_depth=20, min_child_weight=1 ...............\n",
      "[CV]  learning_rate=1, max_depth=20, min_child_weight=1, score=-0.4751244600085576, total=  10.8s\n",
      "[CV] learning_rate=1, max_depth=20, min_child_weight=3 ...............\n",
      "[CV]  learning_rate=1, max_depth=20, min_child_weight=3, score=-0.45095437689830997, total=  10.6s\n",
      "[CV] learning_rate=1, max_depth=20, min_child_weight=3 ...............\n",
      "[CV]  learning_rate=1, max_depth=20, min_child_weight=3, score=-0.445059841146361, total=  10.8s\n",
      "[CV] learning_rate=1, max_depth=20, min_child_weight=3 ...............\n",
      "[CV]  learning_rate=1, max_depth=20, min_child_weight=3, score=-0.45243702887506226, total=  10.9s\n",
      "[CV] learning_rate=1, max_depth=20, min_child_weight=3 ...............\n",
      "[CV]  learning_rate=1, max_depth=20, min_child_weight=3, score=-0.43885769411163994, total=  11.2s\n",
      "[CV] learning_rate=1, max_depth=20, min_child_weight=3 ...............\n",
      "[CV]  learning_rate=1, max_depth=20, min_child_weight=3, score=-0.4543231908111899, total=  10.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  90 out of  90 | elapsed:  9.9min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "       estimator=XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bynode=1, colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
       "       max_delta_step=0, max_depth=3, min_child_weight=1, missing=None,\n",
       "       n_estimators=20, n_jobs=1, nthread=None,\n",
       "       objective='binary:logistic', random_state=0, reg_alpha=0,\n",
       "       reg_lambda=1, scale_pos_weight=1, seed=None, silent=None,\n",
       "       subsample=1, verbosity=1),\n",
       "       fit_params=None, iid='warn', n_jobs=None,\n",
       "       param_grid={'max_depth': [5, 10, 20], 'learning_rate': [0.1, 0.3, 1], 'min_child_weight': [1, 3]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='neg_log_loss', verbose=3)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gb = xgb.XGBClassifier(n_estimators=20)\n",
    "param_grid = { \n",
    "    'max_depth': [5, 10, 20],\n",
    "    'learning_rate': [0.1, 0.3, 1],\n",
    "    'min_child_weight': [1, 3]\n",
    "}\n",
    "grid_search = GridSearchCV(gb, param_grid, cv=5, scoring='neg_log_loss', verbose=3)\n",
    "grid_search.fit(train_data_prepared, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model {'learning_rate': 0.3, 'max_depth': 10, 'min_child_weight': 3} 0.4192162184315547\n"
     ]
    }
   ],
   "source": [
    "print('Best model', grid_search.best_params_, -grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's a bit worse and about twice slower than random forest. Now, try a different, faster library. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 27 candidates, totalling 135 fits\n",
      "[CV] max_depth=10, min_data_in_leaf=20, num_leaves=10 ................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_depth=10, min_data_in_leaf=20, num_leaves=10, score=-0.42486350706433973, total=   0.3s\n",
      "[CV] max_depth=10, min_data_in_leaf=20, num_leaves=10 ................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.4s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_depth=10, min_data_in_leaf=20, num_leaves=10, score=-0.42443667842997734, total=   0.3s\n",
      "[CV] max_depth=10, min_data_in_leaf=20, num_leaves=10 ................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.7s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_depth=10, min_data_in_leaf=20, num_leaves=10, score=-0.41914215694065954, total=   0.3s\n",
      "[CV] max_depth=10, min_data_in_leaf=20, num_leaves=10 ................\n",
      "[CV]  max_depth=10, min_data_in_leaf=20, num_leaves=10, score=-0.4139262958925761, total=   0.3s\n",
      "[CV] max_depth=10, min_data_in_leaf=20, num_leaves=10 ................\n",
      "[CV]  max_depth=10, min_data_in_leaf=20, num_leaves=10, score=-0.42422937525080107, total=   0.3s\n",
      "[CV] max_depth=10, min_data_in_leaf=20, num_leaves=30 ................\n",
      "[CV]  max_depth=10, min_data_in_leaf=20, num_leaves=30, score=-0.41981452681289094, total=   0.4s\n",
      "[CV] max_depth=10, min_data_in_leaf=20, num_leaves=30 ................\n",
      "[CV]  max_depth=10, min_data_in_leaf=20, num_leaves=30, score=-0.42021604560280185, total=   0.4s\n",
      "[CV] max_depth=10, min_data_in_leaf=20, num_leaves=30 ................\n",
      "[CV]  max_depth=10, min_data_in_leaf=20, num_leaves=30, score=-0.41787945097337487, total=   0.4s\n",
      "[CV] max_depth=10, min_data_in_leaf=20, num_leaves=30 ................\n",
      "[CV]  max_depth=10, min_data_in_leaf=20, num_leaves=30, score=-0.41134440842893677, total=   0.3s\n",
      "[CV] max_depth=10, min_data_in_leaf=20, num_leaves=30 ................\n",
      "[CV]  max_depth=10, min_data_in_leaf=20, num_leaves=30, score=-0.4210478550384923, total=   0.3s\n",
      "[CV] max_depth=10, min_data_in_leaf=20, num_leaves=50 ................\n",
      "[CV]  max_depth=10, min_data_in_leaf=20, num_leaves=50, score=-0.4193021494255279, total=   0.4s\n",
      "[CV] max_depth=10, min_data_in_leaf=20, num_leaves=50 ................\n",
      "[CV]  max_depth=10, min_data_in_leaf=20, num_leaves=50, score=-0.42020960876786395, total=   0.5s\n",
      "[CV] max_depth=10, min_data_in_leaf=20, num_leaves=50 ................\n",
      "[CV]  max_depth=10, min_data_in_leaf=20, num_leaves=50, score=-0.41790893259975154, total=   0.5s\n",
      "[CV] max_depth=10, min_data_in_leaf=20, num_leaves=50 ................\n",
      "[CV]  max_depth=10, min_data_in_leaf=20, num_leaves=50, score=-0.4113462674239138, total=   0.5s\n",
      "[CV] max_depth=10, min_data_in_leaf=20, num_leaves=50 ................\n",
      "[CV]  max_depth=10, min_data_in_leaf=20, num_leaves=50, score=-0.420813477622573, total=   0.5s\n",
      "[CV] max_depth=10, min_data_in_leaf=30, num_leaves=10 ................\n",
      "[CV]  max_depth=10, min_data_in_leaf=30, num_leaves=10, score=-0.42484776473540864, total=   0.3s\n",
      "[CV] max_depth=10, min_data_in_leaf=30, num_leaves=10 ................\n",
      "[CV]  max_depth=10, min_data_in_leaf=30, num_leaves=10, score=-0.4239810270876636, total=   0.4s\n",
      "[CV] max_depth=10, min_data_in_leaf=30, num_leaves=10 ................\n",
      "[CV]  max_depth=10, min_data_in_leaf=30, num_leaves=10, score=-0.41910866432388955, total=   0.4s\n",
      "[CV] max_depth=10, min_data_in_leaf=30, num_leaves=10 ................\n",
      "[CV]  max_depth=10, min_data_in_leaf=30, num_leaves=10, score=-0.4136479189030147, total=   0.4s\n",
      "[CV] max_depth=10, min_data_in_leaf=30, num_leaves=10 ................\n",
      "[CV]  max_depth=10, min_data_in_leaf=30, num_leaves=10, score=-0.42430351254772786, total=   0.4s\n",
      "[CV] max_depth=10, min_data_in_leaf=30, num_leaves=30 ................\n",
      "[CV]  max_depth=10, min_data_in_leaf=30, num_leaves=30, score=-0.42000477659707586, total=   0.3s\n",
      "[CV] max_depth=10, min_data_in_leaf=30, num_leaves=30 ................\n",
      "[CV]  max_depth=10, min_data_in_leaf=30, num_leaves=30, score=-0.4209054938923277, total=   0.4s\n",
      "[CV] max_depth=10, min_data_in_leaf=30, num_leaves=30 ................\n",
      "[CV]  max_depth=10, min_data_in_leaf=30, num_leaves=30, score=-0.4161447147966219, total=   0.5s\n",
      "[CV] max_depth=10, min_data_in_leaf=30, num_leaves=30 ................\n",
      "[CV]  max_depth=10, min_data_in_leaf=30, num_leaves=30, score=-0.4107702201701332, total=   0.5s\n",
      "[CV] max_depth=10, min_data_in_leaf=30, num_leaves=30 ................\n",
      "[CV]  max_depth=10, min_data_in_leaf=30, num_leaves=30, score=-0.41986288748467765, total=   0.5s\n",
      "[CV] max_depth=10, min_data_in_leaf=30, num_leaves=50 ................\n",
      "[CV]  max_depth=10, min_data_in_leaf=30, num_leaves=50, score=-0.41845828324246814, total=   0.5s\n",
      "[CV] max_depth=10, min_data_in_leaf=30, num_leaves=50 ................\n",
      "[CV]  max_depth=10, min_data_in_leaf=30, num_leaves=50, score=-0.41986678106237885, total=   0.5s\n",
      "[CV] max_depth=10, min_data_in_leaf=30, num_leaves=50 ................\n",
      "[CV]  max_depth=10, min_data_in_leaf=30, num_leaves=50, score=-0.41560357791188174, total=   0.5s\n",
      "[CV] max_depth=10, min_data_in_leaf=30, num_leaves=50 ................\n",
      "[CV]  max_depth=10, min_data_in_leaf=30, num_leaves=50, score=-0.4106686579398434, total=   0.5s\n",
      "[CV] max_depth=10, min_data_in_leaf=30, num_leaves=50 ................\n",
      "[CV]  max_depth=10, min_data_in_leaf=30, num_leaves=50, score=-0.42083605806282626, total=   0.4s\n",
      "[CV] max_depth=10, min_data_in_leaf=40, num_leaves=10 ................\n",
      "[CV]  max_depth=10, min_data_in_leaf=40, num_leaves=10, score=-0.4256799392385114, total=   0.3s\n",
      "[CV] max_depth=10, min_data_in_leaf=40, num_leaves=10 ................\n",
      "[CV]  max_depth=10, min_data_in_leaf=40, num_leaves=10, score=-0.42559469290691343, total=   0.3s\n",
      "[CV] max_depth=10, min_data_in_leaf=40, num_leaves=10 ................\n",
      "[CV]  max_depth=10, min_data_in_leaf=40, num_leaves=10, score=-0.41921649026066254, total=   0.3s\n",
      "[CV] max_depth=10, min_data_in_leaf=40, num_leaves=10 ................\n",
      "[CV]  max_depth=10, min_data_in_leaf=40, num_leaves=10, score=-0.4136376878137078, total=   0.3s\n",
      "[CV] max_depth=10, min_data_in_leaf=40, num_leaves=10 ................\n",
      "[CV]  max_depth=10, min_data_in_leaf=40, num_leaves=10, score=-0.4243456179816204, total=   0.3s\n",
      "[CV] max_depth=10, min_data_in_leaf=40, num_leaves=30 ................\n",
      "[CV]  max_depth=10, min_data_in_leaf=40, num_leaves=30, score=-0.42097494465030333, total=   0.3s\n",
      "[CV] max_depth=10, min_data_in_leaf=40, num_leaves=30 ................\n",
      "[CV]  max_depth=10, min_data_in_leaf=40, num_leaves=30, score=-0.42034778934993866, total=   0.3s\n",
      "[CV] max_depth=10, min_data_in_leaf=40, num_leaves=30 ................\n",
      "[CV]  max_depth=10, min_data_in_leaf=40, num_leaves=30, score=-0.41608051193340034, total=   0.4s\n",
      "[CV] max_depth=10, min_data_in_leaf=40, num_leaves=30 ................\n",
      "[CV]  max_depth=10, min_data_in_leaf=40, num_leaves=30, score=-0.41143588368489625, total=   0.5s\n",
      "[CV] max_depth=10, min_data_in_leaf=40, num_leaves=30 ................\n",
      "[CV]  max_depth=10, min_data_in_leaf=40, num_leaves=30, score=-0.4211080171476577, total=   0.5s\n",
      "[CV] max_depth=10, min_data_in_leaf=40, num_leaves=50 ................\n",
      "[CV]  max_depth=10, min_data_in_leaf=40, num_leaves=50, score=-0.42016112821899804, total=   0.5s\n",
      "[CV] max_depth=10, min_data_in_leaf=40, num_leaves=50 ................\n",
      "[CV]  max_depth=10, min_data_in_leaf=40, num_leaves=50, score=-0.4202031500801005, total=   0.5s\n",
      "[CV] max_depth=10, min_data_in_leaf=40, num_leaves=50 ................\n",
      "[CV]  max_depth=10, min_data_in_leaf=40, num_leaves=50, score=-0.4151539681611508, total=   0.5s\n",
      "[CV] max_depth=10, min_data_in_leaf=40, num_leaves=50 ................\n",
      "[CV]  max_depth=10, min_data_in_leaf=40, num_leaves=50, score=-0.4110866850225427, total=   0.6s\n",
      "[CV] max_depth=10, min_data_in_leaf=40, num_leaves=50 ................\n",
      "[CV]  max_depth=10, min_data_in_leaf=40, num_leaves=50, score=-0.42268113910782507, total=   0.5s\n",
      "[CV] max_depth=20, min_data_in_leaf=20, num_leaves=10 ................\n",
      "[CV]  max_depth=20, min_data_in_leaf=20, num_leaves=10, score=-0.42486350706433973, total=   0.3s\n",
      "[CV] max_depth=20, min_data_in_leaf=20, num_leaves=10 ................\n",
      "[CV]  max_depth=20, min_data_in_leaf=20, num_leaves=10, score=-0.42443667842997734, total=   0.3s\n",
      "[CV] max_depth=20, min_data_in_leaf=20, num_leaves=10 ................\n",
      "[CV]  max_depth=20, min_data_in_leaf=20, num_leaves=10, score=-0.41914215694065954, total=   0.4s\n",
      "[CV] max_depth=20, min_data_in_leaf=20, num_leaves=10 ................\n",
      "[CV]  max_depth=20, min_data_in_leaf=20, num_leaves=10, score=-0.4139262958925761, total=   0.4s\n",
      "[CV] max_depth=20, min_data_in_leaf=20, num_leaves=10 ................\n",
      "[CV]  max_depth=20, min_data_in_leaf=20, num_leaves=10, score=-0.42422937525080107, total=   0.4s\n",
      "[CV] max_depth=20, min_data_in_leaf=20, num_leaves=30 ................\n",
      "[CV]  max_depth=20, min_data_in_leaf=20, num_leaves=30, score=-0.42098781570849136, total=   0.6s\n",
      "[CV] max_depth=20, min_data_in_leaf=20, num_leaves=30 ................\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_depth=20, min_data_in_leaf=20, num_leaves=30, score=-0.4194514826423095, total=   0.4s\n",
      "[CV] max_depth=20, min_data_in_leaf=20, num_leaves=30 ................\n",
      "[CV]  max_depth=20, min_data_in_leaf=20, num_leaves=30, score=-0.41491341368852247, total=   0.4s\n",
      "[CV] max_depth=20, min_data_in_leaf=20, num_leaves=30 ................\n",
      "[CV]  max_depth=20, min_data_in_leaf=20, num_leaves=30, score=-0.40989116305397205, total=   0.6s\n",
      "[CV] max_depth=20, min_data_in_leaf=20, num_leaves=30 ................\n",
      "[CV]  max_depth=20, min_data_in_leaf=20, num_leaves=30, score=-0.41821582572960014, total=   0.6s\n",
      "[CV] max_depth=20, min_data_in_leaf=20, num_leaves=50 ................\n",
      "[CV]  max_depth=20, min_data_in_leaf=20, num_leaves=50, score=-0.41816178558763717, total=   0.7s\n",
      "[CV] max_depth=20, min_data_in_leaf=20, num_leaves=50 ................\n",
      "[CV]  max_depth=20, min_data_in_leaf=20, num_leaves=50, score=-0.4183746346956301, total=   0.6s\n",
      "[CV] max_depth=20, min_data_in_leaf=20, num_leaves=50 ................\n",
      "[CV]  max_depth=20, min_data_in_leaf=20, num_leaves=50, score=-0.41733459564218744, total=   0.6s\n",
      "[CV] max_depth=20, min_data_in_leaf=20, num_leaves=50 ................\n",
      "[CV]  max_depth=20, min_data_in_leaf=20, num_leaves=50, score=-0.4103291124873058, total=   0.6s\n",
      "[CV] max_depth=20, min_data_in_leaf=20, num_leaves=50 ................\n",
      "[CV]  max_depth=20, min_data_in_leaf=20, num_leaves=50, score=-0.4193575897427325, total=   0.4s\n",
      "[CV] max_depth=20, min_data_in_leaf=30, num_leaves=10 ................\n",
      "[CV]  max_depth=20, min_data_in_leaf=30, num_leaves=10, score=-0.42484776473540864, total=   0.4s\n",
      "[CV] max_depth=20, min_data_in_leaf=30, num_leaves=10 ................\n",
      "[CV]  max_depth=20, min_data_in_leaf=30, num_leaves=10, score=-0.4239810270876636, total=   0.4s\n",
      "[CV] max_depth=20, min_data_in_leaf=30, num_leaves=10 ................\n",
      "[CV]  max_depth=20, min_data_in_leaf=30, num_leaves=10, score=-0.41910866432388955, total=   0.4s\n",
      "[CV] max_depth=20, min_data_in_leaf=30, num_leaves=10 ................\n",
      "[CV]  max_depth=20, min_data_in_leaf=30, num_leaves=10, score=-0.4136479189030147, total=   0.4s\n",
      "[CV] max_depth=20, min_data_in_leaf=30, num_leaves=10 ................\n",
      "[CV]  max_depth=20, min_data_in_leaf=30, num_leaves=10, score=-0.42430351254772786, total=   0.4s\n",
      "[CV] max_depth=20, min_data_in_leaf=30, num_leaves=30 ................\n",
      "[CV]  max_depth=20, min_data_in_leaf=30, num_leaves=30, score=-0.41757626270972514, total=   0.6s\n",
      "[CV] max_depth=20, min_data_in_leaf=30, num_leaves=30 ................\n",
      "[CV]  max_depth=20, min_data_in_leaf=30, num_leaves=30, score=-0.4195925852221594, total=   0.7s\n",
      "[CV] max_depth=20, min_data_in_leaf=30, num_leaves=30 ................\n",
      "[CV]  max_depth=20, min_data_in_leaf=30, num_leaves=30, score=-0.41614759082420577, total=   0.6s\n",
      "[CV] max_depth=20, min_data_in_leaf=30, num_leaves=30 ................\n",
      "[CV]  max_depth=20, min_data_in_leaf=30, num_leaves=30, score=-0.40965510436095176, total=   0.4s\n",
      "[CV] max_depth=20, min_data_in_leaf=30, num_leaves=30 ................\n",
      "[CV]  max_depth=20, min_data_in_leaf=30, num_leaves=30, score=-0.4187046715322479, total=   0.5s\n",
      "[CV] max_depth=20, min_data_in_leaf=30, num_leaves=50 ................\n",
      "[CV]  max_depth=20, min_data_in_leaf=30, num_leaves=50, score=-0.4178219535280824, total=   0.7s\n",
      "[CV] max_depth=20, min_data_in_leaf=30, num_leaves=50 ................\n",
      "[CV]  max_depth=20, min_data_in_leaf=30, num_leaves=50, score=-0.41918002541575433, total=   0.7s\n",
      "[CV] max_depth=20, min_data_in_leaf=30, num_leaves=50 ................\n",
      "[CV]  max_depth=20, min_data_in_leaf=30, num_leaves=50, score=-0.4151253562333386, total=   0.6s\n",
      "[CV] max_depth=20, min_data_in_leaf=30, num_leaves=50 ................\n",
      "[CV]  max_depth=20, min_data_in_leaf=30, num_leaves=50, score=-0.4098191429035634, total=   0.7s\n",
      "[CV] max_depth=20, min_data_in_leaf=30, num_leaves=50 ................\n",
      "[CV]  max_depth=20, min_data_in_leaf=30, num_leaves=50, score=-0.41896832684907476, total=   0.7s\n",
      "[CV] max_depth=20, min_data_in_leaf=40, num_leaves=10 ................\n",
      "[CV]  max_depth=20, min_data_in_leaf=40, num_leaves=10, score=-0.4256799392385114, total=   0.3s\n",
      "[CV] max_depth=20, min_data_in_leaf=40, num_leaves=10 ................\n",
      "[CV]  max_depth=20, min_data_in_leaf=40, num_leaves=10, score=-0.42559469290691343, total=   0.3s\n",
      "[CV] max_depth=20, min_data_in_leaf=40, num_leaves=10 ................\n",
      "[CV]  max_depth=20, min_data_in_leaf=40, num_leaves=10, score=-0.41921649026066254, total=   0.4s\n",
      "[CV] max_depth=20, min_data_in_leaf=40, num_leaves=10 ................\n",
      "[CV]  max_depth=20, min_data_in_leaf=40, num_leaves=10, score=-0.4136376878137078, total=   0.4s\n",
      "[CV] max_depth=20, min_data_in_leaf=40, num_leaves=10 ................\n",
      "[CV]  max_depth=20, min_data_in_leaf=40, num_leaves=10, score=-0.4243456179816204, total=   0.4s\n",
      "[CV] max_depth=20, min_data_in_leaf=40, num_leaves=30 ................\n",
      "[CV]  max_depth=20, min_data_in_leaf=40, num_leaves=30, score=-0.4198571721912521, total=   0.6s\n",
      "[CV] max_depth=20, min_data_in_leaf=40, num_leaves=30 ................\n",
      "[CV]  max_depth=20, min_data_in_leaf=40, num_leaves=30, score=-0.41885244823670204, total=   0.4s\n",
      "[CV] max_depth=20, min_data_in_leaf=40, num_leaves=30 ................\n",
      "[CV]  max_depth=20, min_data_in_leaf=40, num_leaves=30, score=-0.41491305037997733, total=   0.5s\n",
      "[CV] max_depth=20, min_data_in_leaf=40, num_leaves=30 ................\n",
      "[CV]  max_depth=20, min_data_in_leaf=40, num_leaves=30, score=-0.4093047024387022, total=   0.6s\n",
      "[CV] max_depth=20, min_data_in_leaf=40, num_leaves=30 ................\n",
      "[CV]  max_depth=20, min_data_in_leaf=40, num_leaves=30, score=-0.417884588716012, total=   0.6s\n",
      "[CV] max_depth=20, min_data_in_leaf=40, num_leaves=50 ................\n",
      "[CV]  max_depth=20, min_data_in_leaf=40, num_leaves=50, score=-0.4180823048145486, total=   0.5s\n",
      "[CV] max_depth=20, min_data_in_leaf=40, num_leaves=50 ................\n",
      "[CV]  max_depth=20, min_data_in_leaf=40, num_leaves=50, score=-0.4197303298001388, total=   0.7s\n",
      "[CV] max_depth=20, min_data_in_leaf=40, num_leaves=50 ................\n",
      "[CV]  max_depth=20, min_data_in_leaf=40, num_leaves=50, score=-0.4149086814799857, total=   0.8s\n",
      "[CV] max_depth=20, min_data_in_leaf=40, num_leaves=50 ................\n",
      "[CV]  max_depth=20, min_data_in_leaf=40, num_leaves=50, score=-0.40996531086753746, total=   0.5s\n",
      "[CV] max_depth=20, min_data_in_leaf=40, num_leaves=50 ................\n",
      "[CV]  max_depth=20, min_data_in_leaf=40, num_leaves=50, score=-0.4204829095914013, total=   0.7s\n",
      "[CV] max_depth=30, min_data_in_leaf=20, num_leaves=10 ................\n",
      "[CV]  max_depth=30, min_data_in_leaf=20, num_leaves=10, score=-0.42486350706433973, total=   0.4s\n",
      "[CV] max_depth=30, min_data_in_leaf=20, num_leaves=10 ................\n",
      "[CV]  max_depth=30, min_data_in_leaf=20, num_leaves=10, score=-0.42443667842997734, total=   0.4s\n",
      "[CV] max_depth=30, min_data_in_leaf=20, num_leaves=10 ................\n",
      "[CV]  max_depth=30, min_data_in_leaf=20, num_leaves=10, score=-0.41914215694065954, total=   0.3s\n",
      "[CV] max_depth=30, min_data_in_leaf=20, num_leaves=10 ................\n",
      "[CV]  max_depth=30, min_data_in_leaf=20, num_leaves=10, score=-0.4139262958925761, total=   0.4s\n",
      "[CV] max_depth=30, min_data_in_leaf=20, num_leaves=10 ................\n",
      "[CV]  max_depth=30, min_data_in_leaf=20, num_leaves=10, score=-0.42422937525080107, total=   0.4s\n",
      "[CV] max_depth=30, min_data_in_leaf=20, num_leaves=30 ................\n",
      "[CV]  max_depth=30, min_data_in_leaf=20, num_leaves=30, score=-0.41955513210746953, total=   0.7s\n",
      "[CV] max_depth=30, min_data_in_leaf=20, num_leaves=30 ................\n",
      "[CV]  max_depth=30, min_data_in_leaf=20, num_leaves=30, score=-0.4192648401510655, total=   0.6s\n",
      "[CV] max_depth=30, min_data_in_leaf=20, num_leaves=30 ................\n",
      "[CV]  max_depth=30, min_data_in_leaf=20, num_leaves=30, score=-0.41649967292504325, total=   0.6s\n",
      "[CV] max_depth=30, min_data_in_leaf=20, num_leaves=30 ................\n",
      "[CV]  max_depth=30, min_data_in_leaf=20, num_leaves=30, score=-0.40953864285278974, total=   0.6s\n",
      "[CV] max_depth=30, min_data_in_leaf=20, num_leaves=30 ................\n",
      "[CV]  max_depth=30, min_data_in_leaf=20, num_leaves=30, score=-0.4187754986543301, total=   0.7s\n",
      "[CV] max_depth=30, min_data_in_leaf=20, num_leaves=50 ................\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_depth=30, min_data_in_leaf=20, num_leaves=50, score=-0.4199884667723293, total=   0.7s\n",
      "[CV] max_depth=30, min_data_in_leaf=20, num_leaves=50 ................\n",
      "[CV]  max_depth=30, min_data_in_leaf=20, num_leaves=50, score=-0.4184561861629443, total=   0.7s\n",
      "[CV] max_depth=30, min_data_in_leaf=20, num_leaves=50 ................\n",
      "[CV]  max_depth=30, min_data_in_leaf=20, num_leaves=50, score=-0.41682490020605417, total=   0.7s\n",
      "[CV] max_depth=30, min_data_in_leaf=20, num_leaves=50 ................\n",
      "[CV]  max_depth=30, min_data_in_leaf=20, num_leaves=50, score=-0.4105933769747288, total=   0.7s\n",
      "[CV] max_depth=30, min_data_in_leaf=20, num_leaves=50 ................\n",
      "[CV]  max_depth=30, min_data_in_leaf=20, num_leaves=50, score=-0.41946855727324145, total=   0.7s\n",
      "[CV] max_depth=30, min_data_in_leaf=30, num_leaves=10 ................\n",
      "[CV]  max_depth=30, min_data_in_leaf=30, num_leaves=10, score=-0.42484776473540864, total=   0.4s\n",
      "[CV] max_depth=30, min_data_in_leaf=30, num_leaves=10 ................\n",
      "[CV]  max_depth=30, min_data_in_leaf=30, num_leaves=10, score=-0.4239810270876636, total=   0.4s\n",
      "[CV] max_depth=30, min_data_in_leaf=30, num_leaves=10 ................\n",
      "[CV]  max_depth=30, min_data_in_leaf=30, num_leaves=10, score=-0.41910866432388955, total=   0.3s\n",
      "[CV] max_depth=30, min_data_in_leaf=30, num_leaves=10 ................\n",
      "[CV]  max_depth=30, min_data_in_leaf=30, num_leaves=10, score=-0.4136479189030147, total=   0.4s\n",
      "[CV] max_depth=30, min_data_in_leaf=30, num_leaves=10 ................\n",
      "[CV]  max_depth=30, min_data_in_leaf=30, num_leaves=10, score=-0.42430351254772786, total=   0.4s\n",
      "[CV] max_depth=30, min_data_in_leaf=30, num_leaves=30 ................\n",
      "[CV]  max_depth=30, min_data_in_leaf=30, num_leaves=30, score=-0.41765924419680284, total=   0.6s\n",
      "[CV] max_depth=30, min_data_in_leaf=30, num_leaves=30 ................\n",
      "[CV]  max_depth=30, min_data_in_leaf=30, num_leaves=30, score=-0.4189215502466839, total=   0.6s\n",
      "[CV] max_depth=30, min_data_in_leaf=30, num_leaves=30 ................\n",
      "[CV]  max_depth=30, min_data_in_leaf=30, num_leaves=30, score=-0.4146102007525952, total=   0.5s\n",
      "[CV] max_depth=30, min_data_in_leaf=30, num_leaves=30 ................\n",
      "[CV]  max_depth=30, min_data_in_leaf=30, num_leaves=30, score=-0.4092903526362652, total=   0.6s\n",
      "[CV] max_depth=30, min_data_in_leaf=30, num_leaves=30 ................\n",
      "[CV]  max_depth=30, min_data_in_leaf=30, num_leaves=30, score=-0.4181409583436557, total=   0.6s\n",
      "[CV] max_depth=30, min_data_in_leaf=30, num_leaves=50 ................\n",
      "[CV]  max_depth=30, min_data_in_leaf=30, num_leaves=50, score=-0.4187775154929159, total=   0.6s\n",
      "[CV] max_depth=30, min_data_in_leaf=30, num_leaves=50 ................\n",
      "[CV]  max_depth=30, min_data_in_leaf=30, num_leaves=50, score=-0.41830506064490763, total=   0.6s\n",
      "[CV] max_depth=30, min_data_in_leaf=30, num_leaves=50 ................\n",
      "[CV]  max_depth=30, min_data_in_leaf=30, num_leaves=50, score=-0.41674868542080695, total=   0.8s\n",
      "[CV] max_depth=30, min_data_in_leaf=30, num_leaves=50 ................\n",
      "[CV]  max_depth=30, min_data_in_leaf=30, num_leaves=50, score=-0.41019503898818066, total=   0.8s\n",
      "[CV] max_depth=30, min_data_in_leaf=30, num_leaves=50 ................\n",
      "[CV]  max_depth=30, min_data_in_leaf=30, num_leaves=50, score=-0.4185942048368468, total=   0.8s\n",
      "[CV] max_depth=30, min_data_in_leaf=40, num_leaves=10 ................\n",
      "[CV]  max_depth=30, min_data_in_leaf=40, num_leaves=10, score=-0.4256799392385114, total=   0.4s\n",
      "[CV] max_depth=30, min_data_in_leaf=40, num_leaves=10 ................\n",
      "[CV]  max_depth=30, min_data_in_leaf=40, num_leaves=10, score=-0.42559469290691343, total=   0.5s\n",
      "[CV] max_depth=30, min_data_in_leaf=40, num_leaves=10 ................\n",
      "[CV]  max_depth=30, min_data_in_leaf=40, num_leaves=10, score=-0.41921649026066254, total=   0.6s\n",
      "[CV] max_depth=30, min_data_in_leaf=40, num_leaves=10 ................\n",
      "[CV]  max_depth=30, min_data_in_leaf=40, num_leaves=10, score=-0.4136376878137078, total=   0.5s\n",
      "[CV] max_depth=30, min_data_in_leaf=40, num_leaves=10 ................\n",
      "[CV]  max_depth=30, min_data_in_leaf=40, num_leaves=10, score=-0.4243456179816204, total=   0.4s\n",
      "[CV] max_depth=30, min_data_in_leaf=40, num_leaves=30 ................\n",
      "[CV]  max_depth=30, min_data_in_leaf=40, num_leaves=30, score=-0.4195951522715284, total=   0.7s\n",
      "[CV] max_depth=30, min_data_in_leaf=40, num_leaves=30 ................\n",
      "[CV]  max_depth=30, min_data_in_leaf=40, num_leaves=30, score=-0.4195399445394155, total=   0.7s\n",
      "[CV] max_depth=30, min_data_in_leaf=40, num_leaves=30 ................\n",
      "[CV]  max_depth=30, min_data_in_leaf=40, num_leaves=30, score=-0.41470558411657965, total=   0.8s\n",
      "[CV] max_depth=30, min_data_in_leaf=40, num_leaves=30 ................\n",
      "[CV]  max_depth=30, min_data_in_leaf=40, num_leaves=30, score=-0.40961198731690524, total=   0.7s\n",
      "[CV] max_depth=30, min_data_in_leaf=40, num_leaves=30 ................\n",
      "[CV]  max_depth=30, min_data_in_leaf=40, num_leaves=30, score=-0.4182067245688641, total=   0.6s\n",
      "[CV] max_depth=30, min_data_in_leaf=40, num_leaves=50 ................\n",
      "[CV]  max_depth=30, min_data_in_leaf=40, num_leaves=50, score=-0.4207857177135742, total=   0.6s\n",
      "[CV] max_depth=30, min_data_in_leaf=40, num_leaves=50 ................\n",
      "[CV]  max_depth=30, min_data_in_leaf=40, num_leaves=50, score=-0.4186285057961801, total=   0.8s\n",
      "[CV] max_depth=30, min_data_in_leaf=40, num_leaves=50 ................\n",
      "[CV]  max_depth=30, min_data_in_leaf=40, num_leaves=50, score=-0.4163287278004821, total=   1.2s\n",
      "[CV] max_depth=30, min_data_in_leaf=40, num_leaves=50 ................\n",
      "[CV]  max_depth=30, min_data_in_leaf=40, num_leaves=50, score=-0.4092272163752078, total=   0.9s\n",
      "[CV] max_depth=30, min_data_in_leaf=40, num_leaves=50 ................\n",
      "[CV]  max_depth=30, min_data_in_leaf=40, num_leaves=50, score=-0.41954519561158427, total=   1.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 135 out of 135 | elapsed:  1.4min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "       estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,\n",
       "        importance_type='split', learning_rate=0.3, max_depth=-1,\n",
       "        min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,\n",
       "        n_estimators=20, n_jobs=-1, num_leaves=31, objective=None,\n",
       "        random_state=None, reg_alpha=0.0, reg_lambda=0.0, silent=True,\n",
       "        subsample=1.0, subsample_for_bin=200000, subsample_freq=0),\n",
       "       fit_params=None, iid='warn', n_jobs=None,\n",
       "       param_grid={'num_leaves': [10, 30, 50], 'max_depth': [10, 20, 30], 'min_data_in_leaf': [20, 30, 40]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='neg_log_loss', verbose=3)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gb = lgb.LGBMClassifier(n_estimators=20, learning_rate=0.3)\n",
    "param_grid = { \n",
    "    'num_leaves': [10, 30, 50],\n",
    "    'max_depth': [10, 20, 30],\n",
    "    'min_data_in_leaf': [20, 30, 40]\n",
    "}\n",
    "grid_search = GridSearchCV(gb, param_grid, cv=5, scoring='neg_log_loss', verbose=3)\n",
    "grid_search.fit(train_data_prepared, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model {'max_depth': 30, 'min_data_in_leaf': 30, 'num_leaves': 30} 0.4157245527300352\n"
     ]
    }
   ],
   "source": [
    "print('Best model', grid_search.best_params_, -grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wow, the training is really fast. Each model is trained in less than 1s compared to 5-10s with `xgboost`. And the performance is better as well!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All models together\n",
    "Now, I will compare the three algorithms we have using their best tuned parameters, and increase the number of iterations for logistic regression and increase the number of estimators for random forest and gradient boosting to see the best of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best logistic regression: 0.42022368635353213\n",
      "Best random forest: 0.4151497809150225\n",
      "Best gradient boosting: 0.42547294545007136\n"
     ]
    }
   ],
   "source": [
    "logreg = LogisticRegression(solver='lbfgs', penalty='l2', C=0.1, max_iter=10000)\n",
    "s = cross_val_score(logreg, train_data_prepared, labels, scoring='neg_log_loss', cv=5).mean()\n",
    "print('Best logistic regression:', -s)\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=200, max_depth=60, min_samples_leaf=10)\n",
    "s = cross_val_score(rf, train_data_prepared, labels, scoring='neg_log_loss', cv=5).mean()\n",
    "print('Best random forest:', -s)\n",
    "\n",
    "gb = lgb.LGBMClassifier(n_estimators=200, learning_rate=0.3, max_depth=30, min_data_in_leaf=30, num_leaves=30)\n",
    "s = cross_val_score(gb, train_data_prepared, labels, scoring='neg_log_loss', cv=5).mean()\n",
    "print('Best gradient boosting:', -s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`LightGBM` is much faster than random forest from `sklearn`. However, the LGB model with 200 estimators performs worse than the one with 20 estimators. I guess that's the result of overfitting with so many trees. It also means that we can't simply reuse the same parameters for this 100k sample with our full training data. Let's check a few different values first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n",
      "[CV] n_estimators=10 .................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ....... n_estimators=10, score=-0.4202471927697791, total=   0.3s\n",
      "[CV] n_estimators=10 .................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.3s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ....... n_estimators=10, score=-0.4203122004653788, total=   0.4s\n",
      "[CV] n_estimators=10 .................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.8s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ...... n_estimators=10, score=-0.41626140018885055, total=   0.4s\n",
      "[CV] n_estimators=10 .................................................\n",
      "[CV] ....... n_estimators=10, score=-0.4103678291579343, total=   0.4s\n",
      "[CV] n_estimators=10 .................................................\n",
      "[CV] ....... n_estimators=10, score=-0.4194281983707684, total=   0.4s\n",
      "[CV] n_estimators=30 .................................................\n",
      "[CV] ....... n_estimators=30, score=-0.4170367700586952, total=   0.6s\n",
      "[CV] n_estimators=30 .................................................\n",
      "[CV] ........ n_estimators=30, score=-0.419090019426915, total=   0.7s\n",
      "[CV] n_estimators=30 .................................................\n",
      "[CV] ...... n_estimators=30, score=-0.41438973826331166, total=   0.7s\n",
      "[CV] n_estimators=30 .................................................\n",
      "[CV] ....... n_estimators=30, score=-0.4087543781550628, total=   0.5s\n",
      "[CV] n_estimators=30 .................................................\n",
      "[CV] ...... n_estimators=30, score=-0.41800036267232193, total=   0.7s\n",
      "[CV] n_estimators=50 .................................................\n",
      "[CV] ...... n_estimators=50, score=-0.41701122821063313, total=   0.9s\n",
      "[CV] n_estimators=50 .................................................\n",
      "[CV] ...... n_estimators=50, score=-0.42008853667964147, total=   0.9s\n",
      "[CV] n_estimators=50 .................................................\n",
      "[CV] ...... n_estimators=50, score=-0.41508233881968254, total=   1.0s\n",
      "[CV] n_estimators=50 .................................................\n",
      "[CV] ....... n_estimators=50, score=-0.4093807081013099, total=   0.8s\n",
      "[CV] n_estimators=50 .................................................\n",
      "[CV] ...... n_estimators=50, score=-0.41880057647326435, total=   1.0s\n",
      "[CV] n_estimators=100 ................................................\n",
      "[CV] ...... n_estimators=100, score=-0.4209703110573435, total=   1.5s\n",
      "[CV] n_estimators=100 ................................................\n",
      "[CV] ....... n_estimators=100, score=-0.422416005567254, total=   1.9s\n",
      "[CV] n_estimators=100 ................................................\n",
      "[CV] ...... n_estimators=100, score=-0.4196209605012629, total=   1.7s\n",
      "[CV] n_estimators=100 ................................................\n",
      "[CV] ....... n_estimators=100, score=-0.412590177614458, total=   1.5s\n",
      "[CV] n_estimators=100 ................................................\n",
      "[CV] ...... n_estimators=100, score=-0.4229793432262014, total=   1.5s\n",
      "[CV] n_estimators=200 ................................................\n",
      "[CV] ..... n_estimators=200, score=-0.43006096730393334, total=   2.6s\n",
      "[CV] n_estimators=200 ................................................\n",
      "[CV] ..... n_estimators=200, score=-0.42719255882325596, total=   2.5s\n",
      "[CV] n_estimators=200 ................................................\n",
      "[CV] ...... n_estimators=200, score=-0.4234892357749246, total=   2.7s\n",
      "[CV] n_estimators=200 ................................................\n",
      "[CV] ..... n_estimators=200, score=-0.41790660197293455, total=   2.8s\n",
      "[CV] n_estimators=200 ................................................\n",
      "[CV] ...... n_estimators=200, score=-0.4287153633753083, total=   2.5s\n",
      "[CV] n_estimators=500 ................................................\n",
      "[CV] ...... n_estimators=500, score=-0.4489754230765221, total=   5.9s\n",
      "[CV] n_estimators=500 ................................................\n",
      "[CV] ...... n_estimators=500, score=-0.4408479836275046, total=   5.5s\n",
      "[CV] n_estimators=500 ................................................\n",
      "[CV] ...... n_estimators=500, score=-0.4420583106035101, total=   5.9s\n",
      "[CV] n_estimators=500 ................................................\n",
      "[CV] ..... n_estimators=500, score=-0.43318833689176434, total=   5.8s\n",
      "[CV] n_estimators=500 ................................................\n",
      "[CV] ....... n_estimators=500, score=-0.448095837963226, total=   5.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed:  1.2min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model {'n_estimators': 30} 0.41545434743574794\n"
     ]
    }
   ],
   "source": [
    "gb = lgb.LGBMClassifier(n_estimators=20, learning_rate=0.3, max_depth=30, min_data_in_leaf=30, num_leaves=30)\n",
    "param_grid = { \n",
    "    'n_estimators': [10, 30, 50, 100, 200, 500]\n",
    "}\n",
    "grid_search = GridSearchCV(gb, param_grid, cv=5, scoring='neg_log_loss', verbose=3)\n",
    "grid_search.fit(train_data_prepared, labels)\n",
    "\n",
    "print('Best model', grid_search.best_params_, -grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, our best model is gradient boosting with 30 estimators and the logloss is 0.41545. Let's make a submission."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb = lgb.LGBMClassifier(n_estimators=30, learning_rate=0.3, max_depth=30, min_data_in_leaf=30, num_leaves=30)\n",
    "gb.fit(train_data_prepared, labels)\n",
    "preds = gb.predict_proba(test_data_prepared)\n",
    "generate_submission_file(preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Oh, the submission score is worse than before with PL 0.41994 after all the parameters tuning with ensemble models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model(gb, 'all features, gradient boosting with LightGBM', 0.41994, None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will submit the best logistic regression and random forest as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg.fit(train_data_prepared, labels)\n",
    "preds = logreg.predict_proba(test_data_prepared)\n",
    "generate_submission_file(preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Worse than before tuning again!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model(logreg, 'all features, logistic regression', 0.41779, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf.fit(train_data_prepared, labels)\n",
    "preds = rf.predict_proba(test_data_prepared)\n",
    "generate_submission_file(preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PL 0.41339. That is the best score so far. It came from the slowest training though!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model(rf, 'all features, random forest', 0.41339, 1168)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I don't have much time working on this. The explanation I have is the tuned model is overfitted with the training data. As the test data is from a different day. So, we have two options left:\n",
    "- Higher accuracy: random forest\n",
    "- Faster speed: gradient boosting with `LightGBM`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building model with larger training data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, I will use a 1M sample from my EDA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_1m = pd.read_csv('sample.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_data(data):\n",
    "    cat_attribs = ['C1', 'banner_pos', 'site_category', 'app_category', 'device_type', 'device_conn_type', 'site_id', \n",
    "               'site_domain', 'app_id', 'app_domain', 'device_model', 'C14', 'C15', 'C16', 'C17', 'C18', 'C19', 'C20']\n",
    "\n",
    "    # FeatureHasher requires string input instead of number\n",
    "    for a in cat_attribs:\n",
    "        data[a] = data[a].astype('str')\n",
    "    \n",
    "    train_data = data[cat_attribs]\n",
    "    hasher = FeatureHasher(n_features=500, input_type='string')\n",
    "    train_data_prepared = hasher.transform(train_data.values)\n",
    "    \n",
    "    return train_data_prepared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = sample_1m['click']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000000, 500)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_prepared = transform_data(sample_1m)\n",
    "train_data_prepared.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.56 s  624 ms per loop (mean  std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "gb = lgb.LGBMClassifier(n_estimators=30, learning_rate=0.3, max_depth=30, min_data_in_leaf=30, num_leaves=30)\n",
    "%time gb.fit(train_data_prepared, labels)\n",
    "preds = gb.predict_proba(test_data_prepared)\n",
    "generate_submission_file(preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With 10x more training data, we managed to have a more accurate model. PL 0.40892 and ranked 1150."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model(gb, 'all features, random forest, 1m', 0.40892, 1150)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As random forest is too slow. I will only use `LightGBM`. For this assignment, I will try with 10M records instead of a full 40M one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/numpy/lib/arraysetops.py:569: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  mask |= (ar1 == a)\n"
     ]
    }
   ],
   "source": [
    " # Will save the sample to a file for faster loading later\n",
    "train_size = 40428967\n",
    "sample_size = 10**7\n",
    "skip = sorted(np.random.choice(np.arange(1, train_size + 1), train_size - sample_size, replace=False))\n",
    "sample = pd.read_csv('train', skiprows=skip, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = sample['click']\n",
    "train_data_prepared = transform_data(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7min 30s, sys: 9.41 s, total: 7min 39s\n",
      "Wall time: 1min 2s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,\n",
       "        importance_type='split', learning_rate=0.3, max_depth=30,\n",
       "        min_child_samples=20, min_child_weight=0.001, min_data_in_leaf=30,\n",
       "        min_split_gain=0.0, n_estimators=30, n_jobs=-1, num_leaves=30,\n",
       "        objective=None, random_state=None, reg_alpha=0.0, reg_lambda=0.0,\n",
       "        silent=False, subsample=1.0, subsample_for_bin=200000,\n",
       "        subsample_freq=0)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gb = lgb.LGBMClassifier(n_estimators=30, learning_rate=0.3, max_depth=30, min_data_in_leaf=30, num_leaves=30)\n",
    "%time gb.fit(train_data_prepared, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = gb.predict_proba(test_data_prepared)\n",
    "generate_submission_file(preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PL is just 0.40961, which is worse than the model trained with 1m records. That could be because of the same parameters are not optimal for this larger training size. As the model is trained in 1 minute, I decide to spend a bit more time to tune the number of estimators. I had to reduce to 30 because of overfitting with smaller training size, but I think it can be larger now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 3 candidates, totalling 9 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] n_estimators=30 .................................................\n",
      "[CV] ....... n_estimators=30, score=-0.4210155709909052, total=  51.2s\n",
      "[CV] n_estimators=30 .................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  1.1min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ...... n_estimators=30, score=-0.41192013189540827, total=  53.8s\n",
      "[CV] n_estimators=30 .................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:  2.1min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ...... n_estimators=30, score=-0.41250853313175706, total=  54.1s\n",
      "[CV] n_estimators=50 .................................................\n",
      "[CV] ...... n_estimators=50, score=-0.41668256776473844, total= 1.1min\n",
      "[CV] n_estimators=50 .................................................\n",
      "[CV] ...... n_estimators=50, score=-0.41074633448335335, total= 1.1min\n",
      "[CV] n_estimators=50 .................................................\n",
      "[CV] ....... n_estimators=50, score=-0.4109628234789631, total= 1.1min\n",
      "[CV] n_estimators=100 ................................................\n",
      "[CV] ..... n_estimators=100, score=-0.41429869457268587, total= 2.0min\n",
      "[CV] n_estimators=100 ................................................\n",
      "[CV] ...... n_estimators=100, score=-0.4097249608514304, total= 2.0min\n",
      "[CV] n_estimators=100 ................................................\n",
      "[CV] ...... n_estimators=100, score=-0.4088698766056718, total= 2.1min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed: 14.1min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score='raise-deprecating',\n",
       "       estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,\n",
       "        importance_type='split', learning_rate=0.3, max_depth=30,\n",
       "        min_child_samples=20, min_child_weight=0.001, min_data_in_leaf=30,\n",
       "        min_split_gain=0.0, n_estimators=100, n_jobs=-1, num_leaves=30,\n",
       "        objective=None, random_state=None, reg_alpha=0.0, reg_lambda=0.0,\n",
       "        silent=True, subsample=1.0, subsample_for_bin=200000,\n",
       "        subsample_freq=0),\n",
       "       fit_params=None, iid='warn', n_jobs=None,\n",
       "       param_grid={'n_estimators': [30, 50, 100]}, pre_dispatch='2*n_jobs',\n",
       "       refit=True, return_train_score='warn', scoring='neg_log_loss',\n",
       "       verbose=3)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gb = lgb.LGBMClassifier(num_leaves=30, learning_rate=0.3, max_depth=30, min_data_in_leaf=30)\n",
    "param_grid = { \n",
    "    'n_estimators': [30, 50, 100]\n",
    "}\n",
    "grid_search = GridSearchCV(gb, param_grid, cv=3, scoring='neg_log_loss', verbose=3)\n",
    "grid_search.fit(train_data_prepared, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model {'n_estimators': 100} 0.4109645110100144\n"
     ]
    }
   ],
   "source": [
    "print('Best model', grid_search.best_params_, -grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's right, more trees help this time. Now train the final model and submit predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb = lgb.LGBMClassifier(n_estimators=100, learning_rate=0.3, max_depth=30, min_data_in_leaf=30, num_leaves=30)\n",
    "gb.fit(train_data_prepared, labels)\n",
    "\n",
    "preds = gb.predict_proba(test_data_prepared)\n",
    "generate_submission_file(preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My final model has PL 0.40603 and ranked 1127."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
